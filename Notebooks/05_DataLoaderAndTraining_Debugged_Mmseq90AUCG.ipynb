{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Training\n",
    "In this notebook, we will show\n",
    "\n",
    "* How to construct a training and validation dataset that respect External Symmetry. Disconnection on the BC Clan graph will satisfy fairness in External Symmetry; this forms a testing dataset ready for k-fold cross validation.\n",
    "* How to train some models in a 3-fold CV scheme. The training will be done with pytorch taking advantage of its dataloader.\n",
    "* Several effective data augmentation strategies popularised in residual network training.\n",
    "\n",
    "We will illustrate this with training on classification of `A,U,C,G`. The AUCG dataset is much smaller in size than the base/nonsite/phosphate/ribose `S,X,P,R` dataset, but it requires more attention to curate as some structures are solved with interacting bases, but are proven [wildcards](https://droog.gs.washington.edu/parc/images/iupac.html) indicated by the author in the paper. These pdb entries are removed from training to avoid confusion. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# ============== Click Please.Imports\n",
    "import sys\n",
    "import glob\n",
    "import gc\n",
    "import io\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "from scipy import sparse\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import time\n",
    "import tqdm\n",
    "import collections\n",
    "\n",
    "\n",
    "import functools\n",
    "import itertools\n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "import torchvision as tv\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "\n",
    "sys.path.append('../')\n",
    "from NucleicNet.DatasetBuilding.util import *\n",
    "#from NucleicNet.DatasetBuilding.commandReadPdbFtp import ReadBCExternalSymmetry, MakeBcClanGraph\n",
    "from NucleicNet.DatasetBuilding.commandDataFetcherMmseq import FetchIndex, FetchTask, FetchDataset\n",
    "from NucleicNet import Burn, Fuel\n",
    "import NucleicNet.Burn.util\n",
    "import NucleicNet.Burn.M1\n",
    "import  NucleicNet.Burn.DA\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "sns.set_context(\"notebook\")\n",
    "\n",
    "\n",
    "\n",
    "# Turn on cuda optimizer\n",
    "print(torch.backends.cudnn.is_available())\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "# disable debugs NOTE use only after debugging\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "torch.autograd.profiler.profile(False)\n",
    "torch.autograd.profiler.emit_nvtx(False)\n",
    "# Disable gradient tracking\n",
    "#torch.no_grad()\n",
    "#torch.inference_mode()\n",
    "\n",
    "# ================= Click Please. Directories ==================\n",
    "DIR_DerivedData = \"../Database-PDB/DerivedData/\"\n",
    "DIR_Typi = \"../Database-PDB/typi/\"\n",
    "DIR_FuelInput = \"../Database-PDB/feature/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scope of Data\n",
    "\n",
    "The cell below defines the scope of data to be used in training AUCG classifcation. The selection consists of many AND clauses for rejection of PDB entries we deemed unsuitable for our task to avoid garbage-in-garbage-out situations. Many are notated with domain-knowledge dense comments and we did our best to automate the selection. Several groups are discussed below:\n",
    "* Resolution poorer than 3.5 angstrom. Many of these structures are recent cryo-em structures. Many of their sidechains were stubbed (cut away) when authors are not confident in locating the atoms; atom counting programs cannot handle these cases. \n",
    "* Less than 4 nt. Mostly concerning dinucleotide, NTP,NDP,NMP, etc.\n",
    "* Shape-dependent/translocating machinaries. Many RNA-binding protein only recognise RNA due to its secondary structure enveloped in layers of phoshate/ribose. While only some bases interact with the protein, the binding behavior can be sequence independent. These machinaries are usually indicated in `Df_grand[\"Title\"],Df_grand[\"Header\"],Df_grand['NpidbClassification'],`. Also note that PDB curators kindly updates its index every Wednesday, but there can be delay!\n",
    "* Author indicate absence of sequence specificity in article. These can be wildcard base interacting sites or simply the interaction are too marginal or water-mediated that binding behaviour becomes independent of sequence. These are curated by reading into the literature. A quote from the article where the PDB entry is orignated is provided for most of these entries. (Please report an issue if disagree!)\n",
    "* Structures without an accompanying article indexed by Pubmed. There is no way to verfiy subtleties in these entries.\n",
    "* Cases where metal/interfacial inhibitor/tip of hairpin/water-mediated/marginally/modified base interacts with non-canonical-amino-acid engineered protein in solution. (These descriptions are not mutually exclusive nor intersecting...) These concerns induced sequence/non-sequence specificities by zinc cages, chemical , secondary structure recognition and non-canonical amino acids. There are also entries solved with a poly-A/U/C/G oligonucleotiude just as a template for more advanced sequence interaction construction.\n",
    "* NMR multi-states. Some states in solution NMR structures consistently perform poorer than its siblings. We attribute this to the fact that NMR structures are not solved atom-by-atom but rather with a subset of atoms (in the simplest case, constrained by multi-dimensional scaling) and later minimized in a all-atom force field (e.g. simulated annealing). Three states consistently perform better were selected for benchmark.\n",
    "\n",
    "We have updated the curation to year 2021 but we cannot guarentee the curation using flags below will suffice the need of our community thereafter without an update.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(347, 34)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "Df_grand = pd.read_pickle(DIR_DerivedData + \"/DataframeGrand.pkl\")\n",
    "Df_grand = Df_grand.loc[(Df_grand[\"ProNu\"] == \"prot-nuc\") & (Df_grand['Resolution'] <= 3.5) # NOTE you may consider to relax the 3.0 Angstron resolution limit as cryoEM structure w/ ~3.5 angstrom are not uncommon to be modelled in full atom these days\n",
    "                                          & ~(Df_grand['PubmedID'].isnull()) # NOTE ~78 structures. Note that some are recent unindexed by pdb; most are unpublished structures. Some contains large missing loops.\n",
    "                                          & (Df_grand['NucleicAcid'].isin(['rna']))\n",
    "                                          & (pd.notnull(Df_grand['InternalSymmetryBC-95']))\n",
    "                                          & (Df_grand[\"Year\"] <= 2021)\n",
    "                                          & (Df_grand[\"MeanChainLength_Nucleotide\"] >= 4) & (Df_grand[\"SumChainLength_Peptide\"] > 50) \n",
    "                                          # NOTE Some machineries that do not show preference in base or a disproportionately small amount of sites with preference.\n",
    "                                          & ~(Df_grand[\"Title\"].str.contains('ribos|riboz|transcript|polymerase|trna|pseudouridine|srp|signal recognition particle| ribonuclease|rig-i|exosome|spliceosome|csy|csm|cas1|cas9|casc', regex=True, na=False)) \n",
    "                                          & ~(Df_grand[\"Header\"].str.contains('ribos|riboz|transcript|polymerase|trna|pseudouridine|srp|signal recognition particle| ribonuclease|rig-i|exosome|spliceosome|csy|csm|cas1|cas9|casc', regex=True, na=False))\n",
    "#                                          & ~(Df_grand[\"Title\"].str.contains('ribos|riboz|transcript|polymerase|trna|pseudouridine|srp|signal recognition particle| ribonuclease|exosome|spliceosome', regex=True, na=False)) \n",
    "#                                          & ~(Df_grand[\"Header\"].str.contains('ribos|riboz|transcript|polymerase|trna|pseudouridine|srp|signal recognition particle| ribonuclease|exosome|spliceosome', regex=True, na=False))\n",
    "                                          & ~(Df_grand['NpidbClassification'].isin([\"TRANSFERASE/RNA\",'TRANSFERASE','RIBOSOME'])) # ~170 structures\n",
    "\n",
    "                                          # NOTE Author of paper indicate absence of sequence-specificity in article.\n",
    "                                          & ~(Df_grand['Pdbid'].isin(['5o7h','7cyq',\n",
    "                                                                      '5bud','5btb','5bte','5bto',\n",
    "                                                                      '4b3g',\n",
    "                                                                      '6vrb','6vrc',\n",
    "                                                                      '2vnu', # NOTE contain selenomet MSE\n",
    "                                                                      '7c08','7c07', # NOTE zinc cage interaction in zinc finger we cannot handle it\n",
    "                                                                      '3hjw','3hjy','2bgg','1ytu',\n",
    "                                                                      '4d26','4d25','5w3v','6vqv','4qik','4qil',\n",
    "                                                                      '3t5n','3t5q',\n",
    "                                                                      '6cbd','1knz','5id6',\n",
    "                                                                      '2po0','2po1','2po2','2pnz',\n",
    "                                                                      '4oo1','3m7n','3m85',\n",
    "                                                                      '4tyy','4tz0','4tz6','4tyn','4tyw',\n",
    "                                                                      '7bv2','7c42','7c43','7c45','7c47','7c4c','7c4b',\n",
    "                                                                      '6zdp','6zd1','6zd2','6zd6','6zdq','6zdu',\n",
    "                                                                      '4hor','4hoq','4hos','4hot','4hou',\n",
    "                                                                      '6f3h','6w6v',\n",
    "                                                                      '4p3e', '4p3f', '4p3g',\n",
    "                                                                      '5jc3','5jc7','5jcf','5jch',\n",
    "                                                                      '5c9h',\n",
    "                                                                      '3wbm', # NOTE `Although these proteins are abundant and bind both DNA and RNA sequences nonspecifically`\n",
    "                                                                      #'4z4c', '4z4d', '4z4e', '4z4f', '4z4g', '4z4h', '4z4i' , \"appear non-specific\" (??? Check)\n",
    "                                                                      '6bjg', '6bjh', '6bjv', '1rpu',\n",
    "                                                                      '5ws2','6llb',\n",
    "                                                                      '6r7g',\n",
    "                                                                      \n",
    "                                                                      '5n8l', '5n8m', # NOTE `We find that siRNA recognition by the dsRBDs is not sequence-specific but rather depends on the RNA shape. The two dsRBDs can swap their binding sites, giving rise to two equally populated, pseudo-symmetrical complexes, showing that TRBP is not a primary sensor of siRNA asymmetry. `\n",
    "                                                                      '6sjd', # NOTE This is a shape dependent selection where base marginally touch https://genome.cshlp.org/content/30/7/962.full.pdf+html\n",
    "                                                                      '6bbo','6b0b', # NOTE `The human A3H-duplex RNA binding mechanism is mediated in large part by electrostatic contacts between the enzyme and the RNA phosphodiester backbone, as opposed to sequence-specific contacts. `\n",
    "                                                                      '6vqw', '6vqx','6vqv', # NOTE Many Cas system does not have sequence preference such that the machinery is versatile. In this paper they demo Cas7f ` Cas7f and crRNA form multiple hydrogen bonds, which mostly occur between the arginine-rich region (F32, R34, R68, Q95, R168, Q247, Q276, K277, R283, S308, R350) and the sugar-phosphate backbone of crRNA, with only two nucleobases (G[+14], G[+19]) involved (SI Appendix, Fig. S7E). This finding indicates the nonsequence-specific crRNA recognition mode of Cas7f.`\n",
    "                                                                      '3sn2','3snp', #NOTE `Given the similarities in the structures of the IRP1-bound TfR B and Ftn H IREs in this region, and the lack of sequence-specific contacts between IRP1 and the IRE upper helix, the impact of sequence differences in the upper helix on protein binding may relate to effects on helical twist and pitch, and/or to effects on helix stability.`\n",
    "                                                                      #'6uv2','6uv3','6uv4', # NOTE The sequence specificty is debated and likely multilabel RCAYCH especially when a U10 can also bind \n",
    "                                                                      '2gtt','7acs','6yi3', # NOTE `Our model also explains the unspecific nature of N-NTD:RNA interaction. The N-NTD virtually only interacts with the RNA backbone while the bases are, in the case of ssRNA flipped away from the protein, or, in the case of dsRNA involved in base pairing but do not interact with the N-NTD `\n",
    "                                                                      '2wj8', #NOTE `Although the N RNA contacts in the groove are not base-specific, the cavity appears tailored to bind a set of three stacked bases, a feature that appears to be conserved across the Mononegavirales order. Because the bases are averaged out in our crystals, it is not possible to tell from the structure whether certain particular nucleotide sequences would make stronger or weaker interactions within the cavity. `\n",
    "                                                                      '2c0b', '2bx2', '2c4r', # NOTE `Aside from that contact, there is no sequence recognition as such, so it seems that the preference of RNase E for A + U-rich substrates27,28,29 arises mainly through the recognition of the RNA conformation.`\n",
    "                                                                      '3l25','3l26', #NOTE `In the absence of base-specific contacts, it is likely that the interactions observed between the VP35 IID central basic patch and the 8-bp dsRNA are independent of the nucleotide sequence. `\n",
    "                                                                      '4fvu', # NOTE ` By design, each individual strand of RNA is composed of either all-purine or all-pyrimidine bases. The single all-purine and all-pyrimidine strands were annealed to yield dsRNAs that each contain one all-purine and one all-pyrimidine strand. Digestion of dsRNA by Lassa NP is sequence-independent, and thus, there is equal likelihood for either the purine-containing or the pyrimidine-containing strand to be digested. `\n",
    "                                                                      '3ks8','3ks4', # NOTE `This crystal structure shows that each VP35 in the dimer contacts the dsRNA exclusively through the sugar-phosphate backbone and hydrophobic faces of terminal bases, allowing the VP35 dimer to recognize dsRNA in a sequence-independent manner. `\n",
    "                                                                      '2zko', # NOTE `NS1A RBD has the ability to distinguish between dsRNA and dsDNA and recognizes dsRNA in a sequence-independent manner because all the intermolecular contacts are directed towards the sugar-phosphate backbone and 2′-OH groups on the RNA strand`\n",
    "                                                                      '6zlc', '6sx0','6sx2', # NOTE The title of the pdb says non-specific, but the article cited a few specific sequences at the tip of a hairpin not resolved.\n",
    "                                                                      '4e78','4e7a','4e76', #NOTE `None of the nucleobase hydrogen bond acceptors or donors is recognized by the polymerase, indicating sequence-independent recognition by the polymerase. `\n",
    "                                                                      '2ix1','2ix0', # NOTE `The final nucleotides 9–13 are located in a cavity within the RNB domain (Fig. 1c, d), with their five bases clamped between conserved Phe 358 and Tyr 253 (Fig. 2b and Supplementary Fig. S10). Each phosphate group is engaged in one or two hydrogen bonds with protein residues, a characteristic of non-sequence-specific nucleotide recognition sites.`\n",
    "                                                                      '6aay', # NOTE `in order to verify whether A(-37) possesses the base specificity for the pre-crRNA cleavage, A(-37) was mutated to G, C and U, respectively. Results indicate that base type change at this position does not influence the cleavage activity, `\n",
    "                                                                      '3pf4','3pf5', # NOTE `The similar kon values indicate low specificity of Bs-CspB association to all oligonucleotides examined regarding the base composition and the type of ribose rings,`\n",
    "                                                                      '2i91','1yvp','1yvr', # NOTE 2i91 states that `the structure suggests that Ro recognizes helix I of the misfolded RNA as a duplex rather than recognizing any specific sequence.`\n",
    "                                                                      '4oav','4oau', # NOTE Both are resolved with a polyA sequence, but author indicate specificity as recognizes the pattern UN^N. In this case, only the ribose and phosphate are good for use.\n",
    "                                                                      '5z9x','5z9z', # NOTE `Unlike many RRMs, which exhibit strong substrate binding affinities (in the nM range) and sequence specificities, SDN1 RRM binds RNA weakly in a sequence independent mode. `\n",
    "                                                                      '6htu','6sdy','6sdw', # NOTE `Human, Drosophila, and C. elegans Stau were in fact shown to bind dsRNA without apparent sequence specificity in vitro``\n",
    "                                                                      '5y58','5y59','5y5a', # NOTE ` The base of A304 packs against the aliphatic loop L15-16 (between strands β15 and β16) of Ku70 and makes no sequence-specific hydrogen-bonding interactions with the protein (Figure 2F). Substitution of A304 with any other nucleotides had marginal effect on the interaction between Ku and TLC1KBS (Figures 2D and S2). `\n",
    "                                                                      '5ns3','5ns4', # NOTE `Our crystallographic studies confirm the predisposition of Cy3 and Cy5 to stack on the final basepair of double-stranded nucleic acids. We have noted that this is true irrespective of the identity of the sequence of the terminal basepair` \n",
    "                                                                      '5ed2','5ed1','5hp2','5hp3', #NOTE `However, the observed clash is not severe, and the enzyme would be able to accommodate G or C 5′ nearest neighbors by slight structural perturbations, thus explaining why this sequence preference is not an absolute requirement.`\n",
    "                                                                      '6o5f', # NOTE `We found no base-specific recognition of RNA by the protein`\n",
    "                                                                      '7dic','7dcy','7dol','7did', # NOTE `All the samples tested effectively digested a 30-mer ssRNA in a sequence and length independent manner`\n",
    "                                                                      '3rc8',# NOTE `bases are mutually stacked but they form only two hydrogenbonds with the surrounding protein residues. Generally, thesequence conservation of these motifs is lower than in theATP-binding motifs, but some characteristics are common tomost of the SF2 superfamily members.`\n",
    "                                                                        # NOTE `Intriguingly, RIG-I is observed to bind all blunt RNA termini in much the same way, without regard to RNA sequence or the presence of a 5′-triphosphate`\n",
    "                                                                      '4db2','4db4', # NOTE `No protein contacts are observed to the RNA bases of either strand (Fig. 3), consistent with the non-specific RNA binding shown by Mss116p and other DEAD-box proteins1. `\n",
    "                                                                      '7k9e','7k9d','7k9b','7k9c','7kkv', #NOTE `The lack of base-specific interactions, except for the two hydrogen bonds mediated by the first G501 in the tetraloop (Fig. 3B), indicates that the specificity of OapB binding to this region is dictated by the tertiary conformation of the GNRA tetraloop, rather than exact sequence within this tetraloop family.`\n",
    "                                                                      '4ijs','3zla','3zl9', # NOTE from 3zla paper `previous studies have shown that RNA bound to purified soluble recombinant tetramers contains no specific or consensus sequences `\n",
    "                                                                      '7onb', # NOTE The MINX is unmodeled \n",
    "\n",
    "                                                                      '6u6y', # NOTE 4-nt long sequence but only one base is modeled for 3 out of 4 chains; one chain with 3 base but only one in contact.,...\n",
    "                                                                      '5ddo','5ddp','5ddr', '5ddq', # NOTE Riboswitch\n",
    "                                                                      '6e4p', # NOTE polyu `ur FP studies revealed that the RRM domain binds with high affinity to U20 and G20 RNA. Interestingly, however, the RRM bound with significantly higher affinity to poly(G) sequences than poly(U) RNA (Supplemental Figure S2; Figure 5A). These data and the fact that the RRM-U4 structure revealed what appeared to be specific interactions between the protein backbone and the uridine bases, suggested that the RRM might bind poly(G) in a manner distinct from poly(U). `\n",
    "                                                                      '7elc', '7ela', '7elb','7el9', # NOTE This is a polymerase structure, there is no mention of base specific interaction in article https://www.nature.com/articles/s41564-021-00916-w\n",
    "                                                                      '5jrc','5jre','5jr9', # NOTE `Among the nucleic acid interacting residues, mutations of Lys19 had no obvious impact on the cleavage activity of the protein (K19A). However, alanine substitutions of Ser26 and Arg164 all led to weakened cleavage activities of the mutant proteins (S26A and R164A), compared with the WT. Mutations of other residues, including Lys34, Arg124, Arg163 and Tyr168, caused more significant reduction on the cleavage activities of the mutants (K34A, R124A, R163A and Y168A). These results were all consistent with the structural observations.Interestingly, the in vitro cleavage assays with both substrates showed an obvious pattern of products. Comparison with the FAM-labeled markers, including (AC)5 and (AC)5A in Figure 4A, and (GT)5 and (GT)5G in Figure 4B, indicated that NeC3PO preferentially cut after the purine residues. In the NeC3PO:ssRNA structure, the side chain of Phe160 stacked with the nucleobase of A6 (or A6′). Replacing Phe160 with residues that has larger (Trp160 for F160W) or smaller (Ala160 for F160A) side chains showed certain enhancing or weakening effect on the overall cleavage activity of the mutant proteins, compared with the WT. However, the mutant proteins still selectively cut after the purine residues. These observations indicated that Phe160 plays important role in the substrate binding, but is not the main cause of NeC3PO preference to purine.`\n",
    "                                                                      '6wxx','6wxy','6xl1','6wxw','6sce', # NOTE requires short cyclic nucleotide cA4 for specificity \n",
    "                                                                      '3trz', '5udz', '3ts0', # NOTE Part of the recognition unit contains zinc cage\n",
    "                                                                      '6fqr', # NOTE This structure is with CCCC 6gx6 with ACAC `IMP3 RRM12 bound to CCCC and AAAA with similar, but, weak affinity (∼40 µM) (Fig. 2A,B,D). We did not detect the binding, however, to either UUUU or GGGG indicating modest sequence specificity (Supplemental Fig. S4B,C). IMP3 RRM12 bound to ACAC with almost an order of magnitude higher affinity (∼5 µM) indicating its preference for this dinucleotide sequence (Fig. 2C,D).`\n",
    "                                                                      '6sy4', '6sy6', # NOTE This is a very interesting pair. The RNA bound is asymetric but the protein is symetric such that some interactions at Q38 for guanosine is lost `Due to the asymmetric nature of the interface, Arg28′ and Gln38′ from the second protomer neither participate in cation-π interactions (Arg28′) nor in guanine recognition (Gln38′).`\n",
    "                                                                      '7om7','7oma','7om6','7om2','7om9', # NOTE These are dsRNA structure w/o contact with base. The paper does not mention base interaction/specificity either https://www.mdpi.com/1999-4915/13/7/1260/html\n",
    "\n",
    "                                                                      '5udk','5udi','5udj','5udl', # NOTE ` IFIT1 forms a water-filled, positively charged RNA-binding tunnel with a separate hydrophobic extension that unexpectedly engages the cap in multiple conformations (syn and anti) giving rise to a relatively plastic and nonspecific mode of binding, in stark contrast to eIF4E. `\n",
    "                                                                      '5oc6', # NOTE `This domain, typically ∼68 amino acids, is well-known for its functional versatility by means of a particular α1-β1β2β3-α2 canonical structure that allows it to recognize a variety of simple RNA structures ranging from A-form RNA helices to hairpins or tetraloops in shape-dependent manners (7,9,10), even though a sequence-specific mode of recognition has been invoked for a few of them (11,12).`\n",
    "                                                                      '3qsu', # NOTE This is the poly A structure `Binding studies show that Sa Hfq binds (AU) 3 A ≈ (AG) 3 A ≥ (AC) 3 A > (AA) 3 A `\n",
    "                                                                      '1ddl', # NOTE `With both fragments of RNA, binding to protein through hydrogen bonds to either phosphate or ribose groups of the RNA appears not to be sequence-specific. The density seen for base rings fails to suggest any specific nucleotide sequence. `\n",
    "                                                                      '6nut', # NOTE ` We modeled this density as a polymer of six adenosine residues since, as expected, none of these resi-dues makes sequence-specific contacts`\n",
    "                                                                      '3nmr','3nna','3nnc', # NOTE These are selenomethionine substituted structure. 3nnc and 3nnh are not! but 3nnc contains a pseduo symmetric unit with without bound rna `The structures of RRM1/2 in complexes 1 and 2 were determined by multiwavelength anomalous dispersion (MAD) phasing on Se atoms using selenomethionine-labeled protein. The structure of complex 3 was solved by molecular replacement using the refined structure of complex 1 determined at 1.85 Å resolution, as a search model (`\n",
    "                                                                      '4yhw', # NOTE Structure contains a selenomethionine at multiple position eg 417, we cannot handle it `yU4/U6stem II+10nt was slowly added to the SeMet-substituted yPrp3CTF in a 1:1 molar ratio and incubated at 4°C for 15 min. `\n",
    "                                                                      '6uv2', '6uv3', # NOTE “VCAUCH” (Mori et al., 2014) to “RCAYCH.” These two specificities are contested and this paper prefers the latter. I removed the CACACA and ACACCU which contradict Mori et al\n",
    "                                                                      '5d0b','5d0a','5d08', '5t8y' , # NOTE Interactions with base are not found by pymol standard\n",
    "                                                                      '5gjb', # NOTE `he ribose group of ATP bulges out from the binding pocket and no clear electron densities are observed for the adenine group, suggesting that the ZIKV helicase may not have nucleotide specificity for its NTPase activity.`\n",
    "                                                                      '5uz9', # NOTE Largely non-specific `crRNA binding by Cas7f is mediated by non-sequence specific contacts between the sugar-phosphate backbone and residues on the palm (R35, H275, Q277, K278, N281, R284) and web (R169, Q248). `\n",
    "                                                                      '4oq8', '4oq9', '4nia', # NOTE The authors attempted different constraints/restraints to refine a X-ray data, but the single potential base interaction is very marginal  ` It can now be seenthat the base is stacked upon the guanidinium group ofArg125. In addition, the side chain of Asn16 is nearly coplanarwith and approaches the edge of the base, where it could beoriented to form hydrogen bonds with appropriate atoms onthe nucleotide base. The latter feature, as proposed by Seemanet  al.(1976), could thereby provide some degree of basespecificity at the ‘free nucleotide’ position.` \n",
    "                                                                      '1bmv', # NOTE `Interactions with protein are dominated by nonbonding forces with few specific contacts. ` viral cap\n",
    "                                                                      '2jlq', '2jlr', '2jls', '2jlu', '2jlv', '2jlw', '2jlx', '2jly', '2jlz',  # NOTE `As expected, RNA recognition appears to largely occur in a sequence-independent manner as a 13-mer oligoribonucleotide (RNA13) having a different sequence binds to NS3h in essentially the same way as the 12-mer oligoribonucleotide`\n",
    "                                                                      '5ytx','5yts', # NOTE These are solved with suboptimal sequence against sibling at 5ytt, 5ytv`ater, using the iCLIP-Seq method, we mapped the in vivo YB-1–binding sites at a genome-wide level and found that YB-1 preferentially recognizes a UYAUC motif, which closely resembles the binding motif determined by in vitro SELEX (38). In a recent study, the CAUC motif was also identified as a YB-1–binding motif in a fused cell line by `\n",
    "                                                                      '3o3i', # NOTE Only backbone interaction is reported https://www.pnas.org/doi/full/10.1073/pnas.1017762108\n",
    "                                                                      '1gtn', '1gtf', # NOTE the sequence with CC spacer is less tightly held `. In the  complex with CCspacers, where the spacer region is least ordered, the G1 baseis 0.5 Afurther  from  the  protein  than  in  the  other  twostructures. In both the complex with GAGUU and that withGAGCC,  the  second  of  the  two  spacer  nucleotides  is  lessordered than the Ærst.`\n",
    "                                                                      '6muu', # NOTE `The absence of base-specific contacts between protein residues and bases of the crRNA within the 5+1 repeat accounts for the lack of sequence specificity for spacer sequence recognition.`\n",
    "                                                                      '5jji','5jjl','5jjk', # NOTE These set of protein does not interact with the base as the  author argue that the specificty for pyrimidine is induced allosterically \n",
    "                                                                      '7ogk', # NOTE Also note that base are not resolved. `A degenerate ARN-repeat sequence in the RNA substrate interacts with one of the Hfq RNA-binding surfaces, bridging Hfq and PNPase, and indicating a loose sequence preference for carrier assembly. `\n",
    "                                                                      '2izm', # NOTE This structure is resolved with C-10 but G-10 or A-10 is preferred see 2izn ` The –10 base (the bulge) and the –4 base (in the loop) bind similar pockets in the two halves of a dimer, making extensive contacts through hydrogen bonding and hydrophobic interactions ( 5 ). Only an adenosine can be accommodated at the –4 position without a significant reduction of binding ( 7 ). The wild-type TR sequence has an adenosine at position –10, but binding studies have shown that guanosine gives a similar binding constant to adenosine, if the sequence in the stem is changed so that alternative conformations are avoided `\n",
    "                                                                      '5z9w', # NOTE ` Our structure reveals how the Ebola virus nucleocapsid core encapsidates its viral genome, its sequence-independent coordination with RNA by nucleoprotein, and the dynamic transition between the RNA-free and RNA-bound states.`\n",
    "                                                                      '6r9q','6r9p','6r9m','6r9j', '6r9o' # NOTE Not by touch`Crystal structures of Saccharomyces cerevisiae Pan2 in complex with RNA show that, surprisingly, Pan2 does not form canonical base-specific contacts. Instead, it recognizes the intrinsic stacked, helical conformation of poly(A) RNA. `\n",
    "                                                                      ]))\n",
    "                                          # NOTE Unpublished but with pubmedid?\n",
    "                                          & ~(Df_grand['Pdbid'].isin(['3p6y', '2n8m', '3ahu']))\n",
    "                                          # NOTE Cases where metal/interfacial inhibitor/tip of hairpin/water-mediated/marginally/modified base interacts with rna base\n",
    "                                          & ~(Df_grand['Pdbid'].isin([  \n",
    "                                                                        '2lsl',\n",
    "                                                                        \n",
    "                                                                        '5zc9', # NOTE eIF4A1 chemical clamp, water\n",
    "                                                                        '6xki', # NOTE eIF4A1 chemical clamp, water\n",
    "                                                                        \n",
    "                                                                        '4bkk', # NOTE nucleoprotein. There is no mention of base interaction through out the article https://www.microbiologyresearch.org/content/journal/jgv/10.1099/vir.0.053025-0\n",
    "                                                                        '6yrb','6yrq', # NOTE No base interaction mentioned in paper (Check again)\n",
    "                                                                        '1yyw', '2nug', '2nue', '1yz9',# NOTE These is a AU dsRna but prefer GU in other Rnase3 at Q157, 1yz9 makes no contact w/ base\n",
    "                                                                        #'2bs0', # NOTE RNA at interface of two varial capsid protein symmetry mates\n",
    "                                                                        '7n0c','7n0b','7n0d', # NOTE exoribonuclease proof-reading complex but when mismatch the base makes no touch\n",
    "                                                                        '2xgj', # NOTE Helicase w/ no touch at base\n",
    "\n",
    "\n",
    "\n",
    "                                                                        # NOTE Structure solved with Poly-Oligonucleotiude just as a template\n",
    "                                                                        '5wwf', '5ho4', # NOTE These are proteins resolved with same interacting sequence. Its siblings 5wwg 5wwe 5wwx makes most contact with the protein\n",
    "                                                                        '4ht8', '3gib', # NOTE 4ht9 has a higher resolution also with additional uridine sites shown\n",
    "                                                                        '4ijs', # NOTE They use a polyA sequence for simplicity. even though there are interaction with some of the bases.\n",
    "                                                                        '2xbm', # NOTE specificity is in a dinucleotide labeled as G3A\n",
    "                                                                        \n",
    "                                                                        '5eeu', '5eev', '5eew', '5eex', '5eey', '5eez', '5ef0', '5ef1', '5ef2', '5ef3', '1utd', '4v4f', # NOTE While the protein is the same, RNA does not show up in a pseudo symmetry mate. Half and Half. also note a lot of unmodeled nt https://www.rcsb.org/3d-view/5EEV/1\n",
    "                                                                        '6dtd', #  NOTE Cas 13b\n",
    "                                                                        '2zi0', '4erd', # NOTE single helix contact\n",
    "                                                                        '6cf2', # NOTE single helix contact\n",
    "\n",
    "                                                                        #'6mdz', # TODO Ttesting\n",
    "                                                                        '5js2', '5ki6', # NOTE Modified base argonaut\n",
    "                                                                        '6oon','5vm9','5w6v','4kre','4kxt','4olb','4ola', # NOTE Poly-A sequence bound to argonaut\n",
    "                                                                        '5t7b' # NOTE unpublished argonaut\n",
    "                                                                        '4z4c', '4z4d', '4z4e', '4z4f', '4z4g', '4z4h', '4z4i', # NOTE This series of pdbid concerns a water mediated recognition site for adenosine on argonaute `Water-mediated recognition of t1-adenosine anchors Argonaute2 to microRNA targets`\n",
    "                                                                        '5js1', '4w5o', '4w5q', # NOTE Argonaut structure. 4w5o,q has more missing residue than siblings 4w5t,r,n.\n",
    "                                                                        '5wqe', # NOTE multiplebase specific interactions were outlined but most interacts with peptide backbone.\n",
    "                                                                        '5wtk', # NOTE 4 base specific interactions were outlined but the structure is ds and some sidechains e.g. 415-416 were stubbed. we will not include it in training\n",
    "\n",
    "                                                                        # NOTE No specific H bond contact found/does not fulfill Hbond criterion in pymol\n",
    "                                                                        '5ztm', # NOTE The claimed interaction at E172, N175, Q195 does not fulfill H-bond criterion in pymol. Find>Polar Contacts\n",
    "                                                                        '6h5s','6h5q', # NOTE no specific H bond  contact\n",
    "                                                                        '4al7','4al5','4al6', # NOTE base binding site at an unmodeled loop\n",
    "                                                                        '4n2s','4n2q','4me2', # NOTE close but no defined H bond \n",
    "                                                                        '6hyu', '6hyt', # NOTE polyA used and no Hbond specific contact\n",
    "                                                                        \n",
    "\n",
    "\n",
    "                                                                        '5t8y', \n",
    "\n",
    "                                                                        '4z92', # NOTE minimal contact in vriys \n",
    "                                                                        '3hsb', # NOTE a AGAGAG aptamer used but the G does not form specific hbond interactions \n",
    "                                                                        '7bg6','7bg7','7nuq','7nun','7nuo','7nul','7num', # NOTE only stack touched\n",
    "                                                                        '5f9f', '5f98','5f9h','5e3h','3eqt', # NOTE RIG-I recognise modified base m7G `https://www.pnas.org/doi/full/10.1073/pnas.1515152113`\n",
    "                                                                        '5z98','4lg2', # NOTE duplex\n",
    "                                                                        '2ihx', # NOTE Disordered\n",
    "                                                                        '4gv3','4gv6','4gv9','4gve','4g9z', #NOTE backbone only\n",
    "                                                                        '7c06', # NOTE it shares same sequence ith 7c08 but poor?\n",
    "                                                                        \n",
    "                                                                        '3ciy' # NOTE dsRNA\n",
    "                                                                        '5jbg', # NOTE MDA5\n",
    "                                                                        '4ill', '4ilm', '4ilr', # NOTE The RNA strand appears broken??? (bonds too long)\n",
    "                                                                        '6s8b','6s8e','6shb','6sic','6s91','6s6b', # NOTE Backbone only. marginal interaction\n",
    "\n",
    "                                                                        '4peh','4peg','4pei','4pef', # NOTE modified base\n",
    "\n",
    "                                                                        '5jaj','5jb2','5jbg', # NOTE LGP2 duplex\n",
    "                                                                        '4lg2', # NOTE duplex\n",
    "                                                                        '4gha','5m73', # NOTE dsrna\n",
    "\n",
    "                                                                        '3ciy', # NOTE 3.41 angstrom resolution, some sidechain can be highly flexible\n",
    "                                                                        \n",
    "                                                                        \n",
    "\n",
    "                                                                        '3zd6','3zd7', # NOTE Rig I\n",
    "\n",
    "                                                                        '3zc0', # NOTE almost no contact\n",
    "                                                                        '2jlw', # NOTE no contact\n",
    "                                                                        '6ozp', '6ozn', '6ozf','6oze', '6ozg', '6ozh','6ozi', '6ozj', '6ozk', '6ozl', '6ozm',  '6ozo',  '6ozq', \n",
    "                                                                        '6ozr','6ozs', # NOTE through backbone\n",
    "                                                                        '2gje', # NOTE backbone only\n",
    "                                                                        '1f8v', '2bbv', # NOTE backbone only duplex cage in virus capsid\n",
    "\n",
    "                                                                        \n",
    "                                                                        '2mxy', # NOTE solution structure with extra nucleotide compare to 2mz1\n",
    "                                                                       \n",
    "\n",
    "                                                                        '3pkm', # NOTE missing loop\n",
    "\n",
    "                                                                        \n",
    "                                                                        \n",
    "                                                                        '2bx2', # NOTE Marginal\n",
    "\n",
    "                                                                        '6d06', # NOTE modified base dsrna\n",
    "                                                                        '3dh3', # NOTE Modified base\n",
    "                                                                        '7kfn', # NOTE Modified base\n",
    "                                                                        '4i67', # NOTE Modified nt\n",
    "                                                                        '1jbt','1jbs','1jbr',\n",
    "                                                                        '6gc5', #NOTE short strand\n",
    "                                                                        \n",
    "\n",
    "                                                                        \n",
    "                                                                        '5uj2', # NOTE marginal; same family as 4e78\n",
    "\n",
    "                                                                        '7ndh', '7ndi', '7ndj', '7ndk','3d2s', # NOTE require zinc cage\n",
    "                                                                        '6l1w', '1rgo', # NOTE zinc finger    \n",
    "                                                                        '4lj0', '5elk',# NOTE Zn finger short peptide\n",
    "\n",
    "                                                                        '2mqv','2mqt','2ms0','2ms1','2mkn','5u9b','1wwe','1wwf','1wwd','1wwg','2n82','5u9b','1fje','1t4l',\n",
    "                                                                        '2l3c','2lup','1a1t','2mf1','2mf0','1f6u','1ekz','6gbm','2mfe', '2mfg', '2mfh','2mff', '4cio','2jpp',#NOTE Disordered NMR solution structures\n",
    "                                                                        \n",
    "                                                                        '5c0y','5v7c', # NOTE no contact\n",
    "                                                                        '5wea', # NOTE poly A sequence\n",
    "\n",
    "                                                                        '6vff', # NOTE dsrna\n",
    "                                                                        '7krn', '7kro','7krp', # NOTE Helicase dsrna\n",
    "                                                                        '4pmi', # NOTE single helix\n",
    "\n",
    "\n",
    "                                                                        # NOTE Water-mediated or simply in an envelope of water\n",
    "                                                                        '4qoz', '4tuw','4tux','4tv0','4l8r', # NOTE water duplex\n",
    "                                                                        '4mdx', # NOTE water\n",
    "                                                                        '5l2l', # NOTE water\n",
    "                                                                        '5elh', # NOTE water; 5elk has much tighter contact \n",
    "                                                                        '2pjp', '6lt7','6db8','6db9','1c9s','6c6k', '3ts2','5tf6',\n",
    "                                                                        '4n0t','4kzd','6b3k','5e08','5h1l', '1m5o', '6fq3',\n",
    "                                                                        '5gxh','4q9q', '6mwn','5det','6u8d','6u8k', '5gxi','6hau','6d12',\n",
    "                                                                        '2y8y','2y9h','2y8w','4qvc','4f02','6fql','6fq3', # NOTE water\n",
    "                                                                        ]))\n",
    "                                          # NOTE Recently indexed shape-dependent machinery (tRNA/exosome/ribosome), but pdb has not updated its derived data\n",
    "                                          & ~(Df_grand['Pdbid'].isin(['5hr7','5omw','5jea',\n",
    "                                                                      '4o26', # NOTE telomerase\n",
    "                                                                      '5fmz','5epi', # NOTE polymerase\n",
    "                                                                      '6zoj', '6zok', '6zol', # NOTE Ribosome\n",
    "                                                                      '6yan','6yam','6yal', # NOTE ribosome\n",
    "                                                                      '5iwa', # NOTE ribosome\n",
    "                                                                      '5e6m', # NOTE trna\n",
    "                                                                      '5on2','5onh','5on3','5omw','3al0', '3akz', '5e6m', # NOTE tRNA \n",
    "                                                                      '1zl3', # NOTE trna specificity at modified base FLO\n",
    "                                                                      '5ud5','5v6x','4qei','4kqe' # NOTE trna\n",
    "                                                                      '3jam','3jap','3jaq', # NOTE This is a ribosome\n",
    "                                                                      '5ng6', # NOTE Crispr machinery recognise DNA motif TTN but no mention of RNA\n",
    "                                                                      '6sh8','6s6b', '6s8b', '6s8e', '6s91', '6shb', '6sic', # NOTE Crispr machinery no mention of base interaction\n",
    "                                                                    ]))\n",
    "\n",
    "\n",
    "                                          # NOTE \n",
    "                                              ]\n",
    "#print(pd.unique(Df_grand['NucleicAcid']))\n",
    "print(Df_grand.shape)\n",
    "# NOTE Further Remarks on some interesting cases\n",
    "# 3PTO, 3PTX, 3PU0, 3PU1, 3PU4. uses the same nucleocapsid to bind with poly(A,U,C,G), which they use to test how interaction with each kind of base will look like and they propose UAG as an interesting motif to look for https://journals.asm.org/doi/10.1128/JVI.01927-10\n",
    "#                               polyG shows largest amount of interaction polyU shows none However at 3.0 Angstrom, the assignment of N161 can be flipped to make interaction with U27 (seem to support by K164)\n",
    "# 6O1K, 6O1L, 6O1M              `Hfq thus has a structural preference for (ARN)n RNA stretches on its distal side, where N is any nucleotide. `\n",
    "\n",
    "\n",
    "NmrStates = [ '1aud00000004','1aud00000010','1aud00000002',\n",
    "              '2l4100000005','2l4100000011','2l4100000013',\n",
    "              '2xc700000000','2xc700000002','2xc700000006',\n",
    "              '1dz500000007','1dz500000008','1dz500000002',\n",
    "              '1k1g00000001','1k1g00000005','1k1g00000007',\n",
    "              '2ad900000017','2ad900000012','2ad900000019',\n",
    "              '2adb00000004','2adb00000005','2adb00000014',\n",
    "              '2adc00000007','2adc00000001','2adc00000000',\n",
    "              '2c0600000002','2c0600000004','2c0600000009',\n",
    "              '2cjk00000007','2cjk00000008','2cjk00000012',\n",
    "              '2err00000003','2err00000016','2err00000006',\n",
    "              '2fy100000008','2fy100000002','2fy100000000',\n",
    "              '2kfy00000006','2kfy00000003','2kfy00000001',\n",
    "              '2kg000000019','2kg000000012','2kg000000000',\n",
    "              '2kg100000006','2kg100000005','2kg100000003',\n",
    "              '2kh900000007','2kh900000001','2kh900000005',\n",
    "              '2km800000004','2km800000007','2km800000006',\n",
    "              '2kxn00000007','2kxn00000008','2kxn00000001',\n",
    "              '2l2k00000006','2l2k00000002','2l2k00000007',\n",
    "              '2l3j00000008','2l3j00000001','2l3j00000002',\n",
    "              '2l5d00000004','2l5d00000016','2l5d00000008',\n",
    "              '2lbs00000013','2lbs00000009','2lbs00000005',\n",
    "              '2leb00000018','2leb00000000','2leb00000016',\n",
    "              '2lec00000018','2lec00000002','2lec00000007',\n",
    "              '2m8d00000013','2m8d00000003','2m8d00000010',\n",
    "              '2mb000000004','2mb000000018','2mb000000001',\n",
    "              '2mfc00000005','2mfc00000001','2mfc00000015',\n",
    "              '2mfe00000001','2mfe00000002','2mfe00000013',\n",
    "              '2mgz00000017','2mgz00000004','2mgz00000009',\n",
    "              '2mjh00000019','2mjh00000006','2mjh00000009',\n",
    "              '2mki00000005','2mki00000014','2mki00000002',\n",
    "              '2mkk00000006','2mkk00000008','2mkk00000004',\n",
    "              '2mz100000018','2mz100000004','2mz100000003',\n",
    "              '2n7c00000002','2n7c00000010','2n7c00000007',\n",
    "              '2n8l00000003','2n8l00000006','2n8l00000004',\n",
    "              '2rra00000005','2rra00000008','2rra00000009',\n",
    "              '2rs200000018','2rs200000004','2rs200000017',\n",
    "              '2ru300000015','2ru300000011','2ru300000018',\n",
    "              '4cio00000000','4cio00000006','4cio00000008',\n",
    "              '5m8i00000008','5m8i00000014','5m8i00000006',\n",
    "              '5mpg00000011','5mpg00000007','5mpg00000003',\n",
    "              '5mpl00000004','5mpl00000012','5mpl00000002',\n",
    "              '5n8l00000014','5n8l00000018','5n8l00000013',\n",
    "              '5n8m00000015','5n8m00000004','5n8m00000002',\n",
    "              '5x3z00000016','5x3z00000010','5x3z00000001',\n",
    "              '6gbm00000002','6gbm00000000','6gbm00000011',\n",
    "              '6hpj00000013','6hpj00000006','6hpj00000012',\n",
    "              '6snj00000009','6snj00000000','6snj00000002',\n",
    "              '6tph00000004','6tph00000009','6tph00000001',\n",
    "              '7act00000009','7act00000008','7act00000000',\n",
    " ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Options\n",
    "\n",
    "The cell below will define 9 subfolds with around the same datasize for each task. A 3-fold cross validation will be done with each cross fold containing 3 sub fold. In each training cycle 2 subfolds are resserved for validation 1 for testing; the remaining 6 for training. Some options are\n",
    "\n",
    "* Task. `User_Task = \"AUCG\"`.\n",
    "* Number of cross folds to be done. We recommend `n_CrossFold = 9`.\n",
    "* Extent of external symmetry (BC percent) to be considered when we separate folds. We recommend `ClanGraphBcPercent = 90`, but 70 seems also affordable.\n",
    "* Hierarchy of class labels. We recommend a two level hierarchy `TaskNameLabelLogicDict = {\"SXPR\":LabelLogic_level0, \"AUCG\": LabelLogic_level1,}`, but a finer hierarchy `commandDataFetcher.OBSOLETE_TaskNameLabelLogicDict` is also provided if ever needed.\n",
    "* Filter using Derived Data from PDB FTP. We recommend filtering as suggested in `Df_grand`.\n",
    "\n",
    "Some options are machine learning specific hyperparameters and can be tuned in combination if desired. See comments for detail. Some worth mentioning hyperparameters:\n",
    "* Noise in input/hidden layer.\n",
    "* Ghost Batch Normalisation. As the size of dataset grow we can no longer afford small-batch-size (typically 128 or less datapoint) training. \n",
    "* Multi-step cosine scheduler. `SimpleMultistepCosineLRS` This helps to propose multiple models ready for random forest or simple ensemble-averaging.\n",
    "* Label smoothing by neighborhood. This discount voxels at voronoi boundary.\n",
    "* Label smoothing by class. \n",
    "* Bottleneck width. This also allow width tuning as in wideresnet. \n",
    "\n",
    "Some further remarks \n",
    "\n",
    "* When we pack clans of different sizes into the cross folds, we are not aiming at a [bin-packing solution](https://en.wikipedia.org/wiki/Bin_packing_problem), but rather we aim at distributing clans of different sizes evenly among folds. The process will produce a dataframe `TaskClanFoldDf_BC{bc percent}.pkl`, that indicates which pdbids to be included in the fold. \n",
    "* While we cannot load all data into RAM, we will make 6 pass from Storage to RAM, where each pass is restricted to hold `User_DesiredBatchDatasize = 3500000` datapoint. \n",
    "* Class Clan Resampling will be done in minibatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1024, 0.36, False, 'gelu', 16, 0.00175, 5000, 0.03, 1e-06, 0.7, 1e-06, 40, 0.01, 'SimpleMultistepCosineLRS', False, 1.0, 0.0, False, 20, 1.0, 1.5, 0.01, 'CrossEntropyLoss', 0.25, 2.0, 10000000000.0), (1024, 0.36, False, 'gelu', 16, 0.002, 5000, 0.03, 1e-06, 0.7, 1e-06, 40, 0.01, 'SimpleMultistepCosineLRS', False, 1.0, 0.0, False, 20, 1.0, 1.5, 0.01, 'CrossEntropyLoss', 0.25, 2.0, 10000000000.0)]\n"
     ]
    }
   ],
   "source": [
    "n_CrossFold = 9\n",
    "ClanGraphBcPercent = 90\n",
    "User_featuretype = 'altman'\n",
    "\n",
    "User_Task = \"AUCG\"\n",
    "n_row_maxhold = 10000\n",
    "\n",
    "\n",
    "# ================ Collapse. Click Please \n",
    "\n",
    "User_DesiredBatchDatasize    = 3500000 # NOTE This controls the number of new batch of dataset-dataloader being reloaded into memory\n",
    "User_SampleSizePerEpoch_Factor = 1.0 # NOTE This controls how much sample enters into an epoch. if < 1.0, the sampler will make less than User_DesiredBatchDatasize sample to be fed in one epoch\n",
    "\n",
    "User_SampleSizePerEpoch = int(User_DesiredBatchDatasize * User_SampleSizePerEpoch_Factor)\n",
    "n_datasetworker = 16\n",
    "User_ExperiementName = 'AUCG-9CVMm%s'%(ClanGraphBcPercent)\n",
    "\n",
    "DIR_TrainingRoot = \"/home/homingla/Project-NucleicNet/Models/\"\n",
    "DIR_TrainLog = \"/home/homingla/Project-NucleicNet/Models/\" \n",
    "#DIR_Checkpoint = \"/home/homingla/Project-NucleicNet/Models/AUCG_Resnet50Pretrained/lightning_logs/version_4/checkpoints/epoch=4-step=4689.ckpt\"\n",
    "pl.seed_everything(42)\n",
    "Combination_SizeMinibatch = [1024]                  # NOTE We have used Ghost Batch Norm with virtual batch size 128\n",
    "Combination_LabelSmoothing  = [0.36]                # NOTE Default 0.12 when User_NeighborLabelSmoothAngstrom > 0.0. else 0.36\n",
    "Combination_PerformReduction = [False]              # NOTE Default False. True worsen the performance.\n",
    "Combination_Activation = ['gelu']                   # NOTE Default gelu \n",
    "Combination_n_ResnetBlock = [16]                    # NOTE Default 16 \n",
    "Combination_lr = [ 1e-3  * 1.75,  1e-3  * 2.0,]         # NOTE Seemingly a lower MMseq e.g. 30 vs 90 would require larger learning rate. e.g. at 1.0 1e-3\n",
    "Combination_min_lr = [1e-6]                        # NOTE Default 1e-6\n",
    "Combination_CooldownInterval = [5000]               # NOTE Default 2000\n",
    "Combination_AdamW_weight_decay = [0.01 * 3]        # NOTE Default model can tolerate 0.05 but not 0.1. In general 0.01-0.05 are satisfactory. Check Max Performance\n",
    "Combination_Dropoutp = [0.7]                    # NOTE Default 0.7 model can tolerate 0.7\n",
    "Combination_AddL1 = [0.000001]                      # NOTE Default 0 0.0001 poorer than 0.000001 \n",
    "Combination_n_channelbottleneck = [40]          # NOTE Default 40, but 160 leads to simpler model as indicated by L1 of weights? Check\n",
    "Combination_ShiftLrRatio = [0.01]                   # NOTE Unused\n",
    "Combination_User_LrScheduler = [\"SimpleMultistepCosineLRS\"]           # NOTE Default SimpleMultistepCosineLRS CosineAnnealingLR DescendingCosineAnnealingLR_HalfEpoch\n",
    "Combination_User_BiasInSuffixFc = [False]            # NOTE Default True\n",
    "Combination_User_NoiseX = [0.125 *8]                # NOTE Default 1.0 model can tolerate 1.0-1.5\n",
    "Combination_User_NoiseY = [0.0]                     # NOTE Unused\n",
    "Combination_User_Mixup = [False]                    # NOTE Unused. \n",
    "Combination_User_NumReductionComponent = [20]       # NOTE Default. Unused unless PerformReduction = True\n",
    "Combination_User_NoiseZ = [0.125 *8]                # NOTE Default 1.5\n",
    "Combination_User_NeighborLabelSmoothAngstrom = [1.5] # NOTE Default 0.0. \n",
    "Combination_User_InputDropoutp = [0.01]             # NOTE Default 0.1 finalise after tuning all hyperparameters\n",
    "Combination_User_Loss = [\"CrossEntropyLoss\"]        # NOTE CrossEntropyLoss \n",
    "\n",
    "Combination_User_FocalLossAlpha = [0.25]            # NOTE Default 0.25 No effect if focal loss not used.\n",
    "Combination_User_FocalLossGamma = [2.0]             # NOTE Default 2. Note gamma == 0 returns CE\n",
    "Combination_User_GradientClippingValue = [1e10] # clip gradients' global norm to <= this number larger network may need larger clip? default 10000 TODO Test\n",
    "combinations = [\n",
    "                Combination_SizeMinibatch,\n",
    "                Combination_LabelSmoothing,\n",
    "                Combination_PerformReduction,\n",
    "                Combination_Activation,\n",
    "\n",
    "                Combination_n_ResnetBlock,\n",
    "                Combination_lr,\n",
    "                Combination_CooldownInterval,\n",
    "                Combination_AdamW_weight_decay,\n",
    "                Combination_min_lr,\n",
    "                Combination_Dropoutp,\n",
    "                Combination_AddL1,\n",
    "                Combination_n_channelbottleneck,\n",
    "                Combination_ShiftLrRatio,\n",
    "                Combination_User_LrScheduler,\n",
    "                Combination_User_BiasInSuffixFc,\n",
    "                Combination_User_NoiseX,\n",
    "                Combination_User_NoiseY,\n",
    "                Combination_User_Mixup,\n",
    "                Combination_User_NumReductionComponent,\n",
    "                Combination_User_NoiseZ,\n",
    "                Combination_User_NeighborLabelSmoothAngstrom,\n",
    "                Combination_User_InputDropoutp,\n",
    "                Combination_User_Loss,\n",
    "                Combination_User_FocalLossAlpha,\n",
    "                Combination_User_FocalLossGamma,\n",
    "                Combination_User_GradientClippingValue,\n",
    "                ]\n",
    "\n",
    "# result contains all possible combinations.\n",
    "CombinationList = list(itertools.product(*combinations))\n",
    "print(CombinationList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SXPR': {'Base': {'union': ['A', 'U', 'C', 'G'], 'exclu': [], 'intersect': []}, 'Nonsite': {'union': ['nonsite_'], 'exclu': ['F'], 'intersect': []}, 'P': {'union': ['P'], 'exclu': [], 'intersect': []}, 'R': {'union': ['R'], 'exclu': [], 'intersect': []}}, 'AUCG': {'A': {'union': ['A'], 'exclu': [], 'intersect': ['nucsite_']}, 'U': {'union': ['U'], 'exclu': [], 'intersect': ['nucsite_']}, 'C': {'union': ['C'], 'exclu': [], 'intersect': ['nucsite_']}, 'G': {'union': ['G'], 'exclu': [], 'intersect': ['nucsite_']}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ========================= Auto \n",
    "\n",
    "\n",
    "FetchTaskC = FetchTask(DIR_DerivedData = DIR_DerivedData,\n",
    "                              DIR_Typi = DIR_Typi,\n",
    "                              DIR_FuelInput = DIR_FuelInput,\n",
    "                              Df_grand = Df_grand,\n",
    "                              TaskNameLabelLogicDict = None,\n",
    "                              n_row_maxhold = n_row_maxhold)\n",
    "\n",
    "# =========================\n",
    "# Get Definition of Tasks\n",
    "# =========================\n",
    "# NOTE This collects task name and how to get corresponding data in typi \n",
    "TaskNameLabelLogicDict = FetchTaskC.Return_TaskNameLabelLogicDict()\n",
    "#print(TaskNameLabelLogicDict)\n",
    "\n",
    "\n",
    "print(FetchTaskC.TaskNameLabelLogicDict)\n",
    "\n",
    "# =======================\n",
    "# Task Clan Fold Dataframe\n",
    "# =======================\n",
    "# NOTE each element contains 3 tuple train val test\n",
    "CrossFoldDfList = FetchTaskC.Return_CrossFoldDfList(n_CrossFold = n_CrossFold, \n",
    "                                                      ClanGraphBcPercent = ClanGraphBcPercent, \n",
    "                                                      User_Task = User_Task,\n",
    "                                                      Factor_ClampOnMaxSize = 100000,  # NOTE Constraint on datasize of a clan\n",
    "                                                      Factor_ClampOnMultistate = 20,   # NOTE Constriant on number of multistate file read\n",
    "                                                      NmrStates = NmrStates\n",
    "                                                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 0.36, False, 'gelu', 16, 0.00175, 5000, 0.03, 1e-06, 0.7, 1e-06, 40, 0.01, 'SimpleMultistepCosineLRS', False, 1.0, 0.0, False, 20, 1.0, 1.5, 0.01, 'CrossEntropyLoss', 0.25, 2.0, 10000000000.0)\n",
      "Getting TrainValTest batches\n",
      "207 70 36 313\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:00<00:00, 7234.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "264390 264390\n",
      "{0: 20.488312585491137, 1: 10.261026147155574, 2: 12.544115012309305, 3: 29.706546255073405}\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 9936.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "70317 70317\n",
      "{0: 7.313173609915914, 1: 1.146397844338393, 2: 3.8564953882948885, 3: 11.68393315745482}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                       | Params\n",
      "-------------------------------------------------------------\n",
      "0 | nested_module | B1hw_LayerResnetBottleneck | 311 K \n",
      "1 | prefix_layerD | Sequential                 | 0     \n",
      "2 | suffix_layerA | Sequential                 | 0     \n",
      "3 | suffix_layerD | Sequential                 | 230 K \n",
      "4 | suffix_layerZ | Sequential                 | 1.9 K \n",
      "5 | loss          | CrossEntropyLoss           | 0     \n",
      "-------------------------------------------------------------\n",
      "543 K     Trainable params\n",
      "0         Non-trainable params\n",
      "543 K     Total params\n",
      "2.173     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/homingla/Software/anaconda3/envs/Nucl/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:633: UserWarning: Your `val_dataloader` has `shuffle=True`, it is strongly recommended that you turn this off for val/test/predict dataloaders.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  94%|█████████▍| 7908/8417 [24:08<01:33,  5.46it/s, loss=0.955, v_num=2_43, train_loss_s=0.952, val_loss_s=1.440]10000 20000 0.0017490000000000001\n",
      "Epoch 14: 100%|██████████| 8417/8417 [26:26<00:00,  5.30it/s, loss=0.939, v_num=2_43, train_loss_s=0.941, val_loss_s=1.480]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  2.3589e+04     \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1572.1         \t|15             \t|  2.3582e+04     \t|  99.973         \t|\n",
      "run_training_batch                 \t|  0.34322        \t|51255          \t|  1.7592e+04     \t|  74.578         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.34182        \t|51255          \t|  1.752e+04      \t|  74.272         \t|\n",
      "training_step_and_backward         \t|  0.17553        \t|51255          \t|  8996.9         \t|  38.141         \t|\n",
      "backward                           \t|  0.10489        \t|51255          \t|  5376.0         \t|  22.791         \t|\n",
      "evaluation_step_and_end            \t|  0.050878       \t|75002          \t|  3815.9         \t|  16.177         \t|\n",
      "validation_step                    \t|  0.050777       \t|75002          \t|  3808.4         \t|  16.145         \t|\n",
      "model_forward                      \t|  0.068771       \t|51255          \t|  3524.8         \t|  14.943         \t|\n",
      "training_step                      \t|  0.068538       \t|51255          \t|  3512.9         \t|  14.892         \t|\n",
      "get_validate_batch                 \t|  0.0049645      \t|76500          \t|  379.79         \t|  1.61           \t|\n",
      "fetch_next_validate_batch          \t|  0.0049349      \t|76500          \t|  377.52         \t|  1.6004         \t|\n",
      "on_train_batch_end                 \t|  0.0032654      \t|51255          \t|  167.37         \t|  0.70952        \t|\n",
      "on_validation_batch_end            \t|  0.0016718      \t|75002          \t|  125.39         \t|  0.53157        \t|\n",
      "zero_grad                          \t|  0.00183        \t|51255          \t|  93.796         \t|  0.39763        \t|\n",
      "on_train_batch_start               \t|  0.0016614      \t|51255          \t|  85.155         \t|  0.361          \t|\n",
      "on_validation_end                  \t|  0.03812        \t|1501           \t|  57.219         \t|  0.24257        \t|\n",
      "evaluation_batch_to_device         \t|  0.00058815     \t|75002          \t|  44.112         \t|  0.18701        \t|\n",
      "get_train_batch                    \t|  0.00080841     \t|51270          \t|  41.447         \t|  0.17571        \t|\n",
      "fetch_next_train_batch             \t|  0.00077895     \t|51270          \t|  39.937         \t|  0.16931        \t|\n",
      "training_batch_to_device           \t|  0.00035045     \t|51255          \t|  17.962         \t|  0.076148       \t|\n",
      "on_validation_start                \t|  0.0049375      \t|1501           \t|  7.4112         \t|  0.031419       \t|\n",
      "on_validation_model_eval           \t|  0.0047314      \t|1501           \t|  7.1019         \t|  0.030107       \t|\n",
      "on_validation_batch_start          \t|  3.6798e-05     \t|75002          \t|  2.7599         \t|  0.0117         \t|\n",
      "on_batch_start                     \t|  4.1699e-05     \t|51255          \t|  2.1373         \t|  0.0090607      \t|\n",
      "on_batch_end                       \t|  3.8896e-05     \t|51255          \t|  1.9936         \t|  0.0084517      \t|\n",
      "on_after_backward                  \t|  3.878e-05      \t|51255          \t|  1.9876         \t|  0.0084263      \t|\n",
      "on_before_zero_grad                \t|  3.7562e-05     \t|51255          \t|  1.9252         \t|  0.0081617      \t|\n",
      "on_before_backward                 \t|  3.2894e-05     \t|51255          \t|  1.686          \t|  0.0071476      \t|\n",
      "on_before_optimizer_step           \t|  3.24e-05       \t|51255          \t|  1.6607         \t|  0.0070402      \t|\n",
      "validation_step_end                \t|  8.5833e-06     \t|75002          \t|  0.64377        \t|  0.0027292      \t|\n",
      "training_step_end                  \t|  1.0741e-05     \t|51255          \t|  0.55055        \t|  0.002334       \t|\n",
      "on_validation_epoch_end            \t|  4.775e-05      \t|1501           \t|  0.071673       \t|  0.00030385     \t|\n",
      "get_sanity_check_batch             \t|  0.017017       \t|3              \t|  0.051051       \t|  0.00021642     \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.016958       \t|3              \t|  0.050873       \t|  0.00021567     \t|\n",
      "on_validation_epoch_start          \t|  3.3122e-05     \t|1501           \t|  0.049717       \t|  0.00021077     \t|\n",
      "on_epoch_start                     \t|  3.1433e-05     \t|1516           \t|  0.047652       \t|  0.00020201     \t|\n",
      "on_epoch_end                       \t|  3.0696e-05     \t|1516           \t|  0.046535       \t|  0.00019728     \t|\n",
      "on_train_epoch_start               \t|  0.0026091      \t|15             \t|  0.039136       \t|  0.00016591     \t|\n",
      "on_pretrain_routine_start          \t|  0.020109       \t|1              \t|  0.020109       \t|  8.5249e-05     \t|\n",
      "on_train_epoch_end                 \t|  0.0013026      \t|15             \t|  0.019539       \t|  8.2834e-05     \t|\n",
      "on_train_start                     \t|  0.011487       \t|1              \t|  0.011487       \t|  4.8697e-05     \t|\n",
      "configure_optimizers               \t|  0.0040285      \t|1              \t|  0.0040285      \t|  1.7078e-05     \t|\n",
      "on_sanity_check_start              \t|  0.0018449      \t|1              \t|  0.0018449      \t|  7.8214e-06     \t|\n",
      "on_train_end                       \t|  0.00091941     \t|1              \t|  0.00091941     \t|  3.8977e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  6.0141e-05     \t|1              \t|  6.0141e-05     \t|  2.5496e-07     \t|\n",
      "on_sanity_check_end                \t|  5.789e-05      \t|1              \t|  5.789e-05      \t|  2.4542e-07     \t|\n",
      "on_fit_start                       \t|  5.303e-05      \t|1              \t|  5.303e-05      \t|  2.2481e-07     \t|\n",
      "on_configure_sharded_model         \t|  5.0309e-05     \t|1              \t|  5.0309e-05     \t|  2.1328e-07     \t|\n",
      "teardown                           \t|  4.9681e-05     \t|1              \t|  4.9681e-05     \t|  2.1062e-07     \t|\n",
      "setup                              \t|  4.9672e-05     \t|1              \t|  4.9672e-05     \t|  2.1058e-07     \t|\n",
      "on_fit_end                         \t|  4.8636e-05     \t|1              \t|  4.8636e-05     \t|  2.0619e-07     \t|\n",
      "on_pretrain_routine_end            \t|  4.141e-05      \t|1              \t|  4.141e-05      \t|  1.7555e-07     \t|\n",
      "configure_callbacks                \t|  3.079e-05      \t|1              \t|  3.079e-05      \t|  1.3053e-07     \t|\n",
      "on_train_dataloader                \t|  1.6091e-05     \t|1              \t|  1.6091e-05     \t|  6.8215e-08     \t|\n",
      "on_val_dataloader                  \t|  8.64e-06       \t|1              \t|  8.64e-06       \t|  3.6628e-08     \t|\n",
      "configure_sharded_model            \t|  8.419e-06      \t|1              \t|  8.419e-06      \t|  3.5691e-08     \t|\n",
      "prepare_data                       \t|  7.704e-06      \t|1              \t|  7.704e-06      \t|  3.266e-08      \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 0.36, False, 'gelu', 16, 0.00175, 5000, 0.03, 1e-06, 0.7, 1e-06, 40, 0.01, 'SimpleMultistepCosineLRS', False, 1.0, 0.0, False, 20, 1.0, 1.5, 0.01, 'CrossEntropyLoss', 0.25, 2.0, 10000000000.0)\n",
      "Getting TrainValTest batches\n",
      "210 70 33 313\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [00:00<00:00, 9309.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "188273 188273\n",
      "{0: 17.469871056859304, 1: 6.685181895191551, 2: 12.356958375266036, 3: 31.487988672686495}\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 2513.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "124872 124872\n",
      "{0: 6.8075900442477435, 1: 2.9074466971687696, 2: 4.042690983164212, 3: 8.242272275428633}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                       | Params\n",
      "-------------------------------------------------------------\n",
      "0 | nested_module | B1hw_LayerResnetBottleneck | 311 K \n",
      "1 | prefix_layerD | Sequential                 | 0     \n",
      "2 | suffix_layerA | Sequential                 | 0     \n",
      "3 | suffix_layerD | Sequential                 | 230 K \n",
      "4 | suffix_layerZ | Sequential                 | 1.9 K \n",
      "5 | loss          | CrossEntropyLoss           | 0     \n",
      "-------------------------------------------------------------\n",
      "543 K     Trainable params\n",
      "0         Non-trainable params\n",
      "543 K     Total params\n",
      "2.173     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  94%|█████████▍| 5955/6317 [22:51<01:23,  4.34it/s, loss=0.937, v_num=4_45, train_loss_s=0.939, val_loss_s=1.460]10000 20000 0.0017490000000000001\n",
      "Epoch 14: 100%|██████████| 6317/6317 [24:49<00:00,  4.24it/s, loss=0.926, v_num=4_45, train_loss_s=0.923, val_loss_s=1.500]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  2.2236e+04     \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1482.2         \t|15             \t|  2.2232e+04     \t|  99.984         \t|\n",
      "run_training_batch                 \t|  0.34284        \t|51255          \t|  1.7572e+04     \t|  79.026         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.3414         \t|51255          \t|  1.7498e+04     \t|  78.694         \t|\n",
      "training_step_and_backward         \t|  0.17557        \t|51255          \t|  8999.0         \t|  40.47          \t|\n",
      "backward                           \t|  0.1046         \t|51255          \t|  5361.4         \t|  24.111         \t|\n",
      "model_forward                      \t|  0.069083       \t|51255          \t|  3540.8         \t|  15.924         \t|\n",
      "training_step                      \t|  0.068848       \t|51255          \t|  3528.8         \t|  15.87          \t|\n",
      "evaluation_step_and_end            \t|  0.058141       \t|43502          \t|  2529.2         \t|  11.374         \t|\n",
      "validation_step                    \t|  0.058036       \t|43502          \t|  2524.7         \t|  11.354         \t|\n",
      "get_validate_batch                 \t|  0.0091987      \t|45000          \t|  413.94         \t|  1.8616         \t|\n",
      "fetch_next_validate_batch          \t|  0.0091675      \t|45000          \t|  412.54         \t|  1.8552         \t|\n",
      "on_train_batch_end                 \t|  0.0033053      \t|51255          \t|  169.41         \t|  0.76188        \t|\n",
      "zero_grad                          \t|  0.0018431      \t|51255          \t|  94.467         \t|  0.42483        \t|\n",
      "on_train_batch_start               \t|  0.0016678      \t|51255          \t|  85.483         \t|  0.38443        \t|\n",
      "on_validation_batch_end            \t|  0.0017283      \t|43502          \t|  75.186         \t|  0.33813        \t|\n",
      "on_validation_end                  \t|  0.03469        \t|1501           \t|  52.069         \t|  0.23416        \t|\n",
      "get_train_batch                    \t|  0.00078635     \t|51270          \t|  40.316         \t|  0.18131        \t|\n",
      "fetch_next_train_batch             \t|  0.00075687     \t|51270          \t|  38.804         \t|  0.17451        \t|\n",
      "evaluation_batch_to_device         \t|  0.00058769     \t|43502          \t|  25.566         \t|  0.11497        \t|\n",
      "training_batch_to_device           \t|  0.00035727     \t|51255          \t|  18.312         \t|  0.082353       \t|\n",
      "on_validation_model_eval           \t|  0.0048079      \t|1501           \t|  7.2166         \t|  0.032454       \t|\n",
      "on_validation_start                \t|  0.0045025      \t|1501           \t|  6.7583         \t|  0.030393       \t|\n",
      "on_batch_start                     \t|  4.2061e-05     \t|51255          \t|  2.1558         \t|  0.0096952      \t|\n",
      "on_after_backward                  \t|  3.9635e-05     \t|51255          \t|  2.0315         \t|  0.009136       \t|\n",
      "on_batch_end                       \t|  3.9059e-05     \t|51255          \t|  2.0019         \t|  0.0090031      \t|\n",
      "on_before_zero_grad                \t|  3.7777e-05     \t|51255          \t|  1.9363         \t|  0.0087077      \t|\n",
      "on_before_backward                 \t|  3.3245e-05     \t|51255          \t|  1.704          \t|  0.0076632      \t|\n",
      "on_validation_batch_start          \t|  3.8878e-05     \t|43502          \t|  1.6913         \t|  0.007606       \t|\n",
      "on_before_optimizer_step           \t|  3.2662e-05     \t|51255          \t|  1.6741         \t|  0.0075288      \t|\n",
      "training_step_end                  \t|  1.0823e-05     \t|51255          \t|  0.55474        \t|  0.0024947      \t|\n",
      "validation_step_end                \t|  9.1023e-06     \t|43502          \t|  0.39597        \t|  0.0017807      \t|\n",
      "on_validation_epoch_end            \t|  4.9094e-05     \t|1501           \t|  0.07369        \t|  0.0003314      \t|\n",
      "get_sanity_check_batch             \t|  0.019087       \t|3              \t|  0.057262       \t|  0.00025752     \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.019032       \t|3              \t|  0.057095       \t|  0.00025677     \t|\n",
      "on_validation_epoch_start          \t|  3.327e-05      \t|1501           \t|  0.049939       \t|  0.00022458     \t|\n",
      "on_epoch_start                     \t|  3.1334e-05     \t|1516           \t|  0.047502       \t|  0.00021363     \t|\n",
      "on_epoch_end                       \t|  3.098e-05      \t|1516           \t|  0.046966       \t|  0.00021121     \t|\n",
      "on_train_epoch_start               \t|  0.0024393      \t|15             \t|  0.03659        \t|  0.00016455     \t|\n",
      "on_pretrain_routine_start          \t|  0.019915       \t|1              \t|  0.019915       \t|  8.9561e-05     \t|\n",
      "on_train_epoch_end                 \t|  0.0012963      \t|15             \t|  0.019444       \t|  8.7444e-05     \t|\n",
      "on_train_start                     \t|  0.015613       \t|1              \t|  0.015613       \t|  7.0213e-05     \t|\n",
      "configure_optimizers               \t|  0.0036749      \t|1              \t|  0.0036749      \t|  1.6527e-05     \t|\n",
      "on_sanity_check_start              \t|  0.0014373      \t|1              \t|  0.0014373      \t|  6.4639e-06     \t|\n",
      "on_train_end                       \t|  0.00096895     \t|1              \t|  0.00096895     \t|  4.3575e-06     \t|\n",
      "on_fit_end                         \t|  5.3348e-05     \t|1              \t|  5.3348e-05     \t|  2.3992e-07     \t|\n",
      "on_sanity_check_end                \t|  4.9781e-05     \t|1              \t|  4.9781e-05     \t|  2.2387e-07     \t|\n",
      "teardown                           \t|  4.3404e-05     \t|1              \t|  4.3404e-05     \t|  1.952e-07      \t|\n",
      "on_pretrain_routine_end            \t|  4.1964e-05     \t|1              \t|  4.1964e-05     \t|  1.8872e-07     \t|\n",
      "on_before_accelerator_backend_setup\t|  4.1569e-05     \t|1              \t|  4.1569e-05     \t|  1.8694e-07     \t|\n",
      "on_configure_sharded_model         \t|  3.8274e-05     \t|1              \t|  3.8274e-05     \t|  1.7213e-07     \t|\n",
      "on_fit_start                       \t|  3.6222e-05     \t|1              \t|  3.6222e-05     \t|  1.629e-07      \t|\n",
      "setup                              \t|  3.4337e-05     \t|1              \t|  3.4337e-05     \t|  1.5442e-07     \t|\n",
      "configure_callbacks                \t|  1.539e-05      \t|1              \t|  1.539e-05      \t|  6.9212e-08     \t|\n",
      "on_train_dataloader                \t|  1.0851e-05     \t|1              \t|  1.0851e-05     \t|  4.8799e-08     \t|\n",
      "configure_sharded_model            \t|  9.893e-06      \t|1              \t|  9.893e-06      \t|  4.4491e-08     \t|\n",
      "on_val_dataloader                  \t|  7.612e-06      \t|1              \t|  7.612e-06      \t|  3.4233e-08     \t|\n",
      "prepare_data                       \t|  7.006e-06      \t|1              \t|  7.006e-06      \t|  3.1507e-08     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 0.36, False, 'gelu', 16, 0.00175, 5000, 0.03, 1e-06, 0.7, 1e-06, 40, 0.01, 'SimpleMultistepCosineLRS', False, 1.0, 0.0, False, 20, 1.0, 1.5, 0.01, 'CrossEntropyLoss', 0.25, 2.0, 10000000000.0)\n",
      "Getting TrainValTest batches\n",
      "209 73 31 313\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:00<00:00, 6296.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "272361 272361\n",
      "{0: 20.71123523471334, 1: 8.295204926323487, 2: 11.501889978546158, 3: 30.491669860350058}\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 7043.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "61392 61392\n",
      "{0: 5.039109713616278, 1: 2.8233504771883333, 2: 4.847154990105763, 3: 10.290384819090676}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                       | Params\n",
      "-------------------------------------------------------------\n",
      "0 | nested_module | B1hw_LayerResnetBottleneck | 311 K \n",
      "1 | prefix_layerD | Sequential                 | 0     \n",
      "2 | suffix_layerA | Sequential                 | 0     \n",
      "3 | suffix_layerD | Sequential                 | 230 K \n",
      "4 | suffix_layerZ | Sequential                 | 1.9 K \n",
      "5 | loss          | CrossEntropyLoss           | 0     \n",
      "-------------------------------------------------------------\n",
      "543 K     Trainable params\n",
      "0         Non-trainable params\n",
      "543 K     Total params\n",
      "2.173     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  94%|█████████▍| 8652/9217 [24:49<01:37,  5.81it/s, loss=0.952, v_num=6_47, train_loss_s=0.952, val_loss_s=1.480]10000 20000 0.0017490000000000001\n",
      "Epoch 14: 100%|██████████| 9217/9217 [27:07<00:00,  5.66it/s, loss=0.94, v_num=6_47, train_loss_s=0.931, val_loss_s=1.490]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  2.4183e+04     \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1611.9         \t|15             \t|  2.4179e+04     \t|  99.984         \t|\n",
      "run_training_batch                 \t|  0.344          \t|51255          \t|  1.7632e+04     \t|  72.91          \t|\n",
      "optimizer_step_with_closure_0      \t|  0.34255        \t|51255          \t|  1.7557e+04     \t|  72.602         \t|\n",
      "training_step_and_backward         \t|  0.1764         \t|51255          \t|  9041.6         \t|  37.388         \t|\n",
      "backward                           \t|  0.105          \t|51255          \t|  5381.5         \t|  22.254         \t|\n",
      "evaluation_step_and_end            \t|  0.049575       \t|87002          \t|  4313.1         \t|  17.835         \t|\n",
      "validation_step                    \t|  0.049472       \t|87002          \t|  4304.1         \t|  17.798         \t|\n",
      "model_forward                      \t|  0.069505       \t|51255          \t|  3562.5         \t|  14.732         \t|\n",
      "training_step                      \t|  0.06927        \t|51255          \t|  3550.4         \t|  14.682         \t|\n",
      "get_validate_batch                 \t|  0.0040104      \t|88500          \t|  354.92         \t|  1.4676         \t|\n",
      "fetch_next_validate_batch          \t|  0.0039811      \t|88500          \t|  352.33         \t|  1.4569         \t|\n",
      "on_train_batch_end                 \t|  0.0031448      \t|51255          \t|  161.19         \t|  0.66654        \t|\n",
      "on_validation_batch_end            \t|  0.0015399      \t|87002          \t|  133.97         \t|  0.55399        \t|\n",
      "zero_grad                          \t|  0.0018587      \t|51255          \t|  95.266         \t|  0.39394        \t|\n",
      "on_train_batch_start               \t|  0.0016804      \t|51255          \t|  86.127         \t|  0.35615        \t|\n",
      "on_validation_end                  \t|  0.048656       \t|1501           \t|  73.032         \t|  0.302          \t|\n",
      "evaluation_batch_to_device         \t|  0.00057956     \t|87002          \t|  50.423         \t|  0.20851        \t|\n",
      "get_train_batch                    \t|  0.00082769     \t|51270          \t|  42.436         \t|  0.17548        \t|\n",
      "fetch_next_train_batch             \t|  0.0007983      \t|51270          \t|  40.929         \t|  0.16925        \t|\n",
      "training_batch_to_device           \t|  0.00035545     \t|51255          \t|  18.219         \t|  0.075338       \t|\n",
      "on_validation_start                \t|  0.0049701      \t|1501           \t|  7.4601         \t|  0.030849       \t|\n",
      "on_validation_model_eval           \t|  0.0048414      \t|1501           \t|  7.267          \t|  0.03005        \t|\n",
      "on_validation_batch_start          \t|  3.6147e-05     \t|87002          \t|  3.1449         \t|  0.013005       \t|\n",
      "on_batch_start                     \t|  4.1894e-05     \t|51255          \t|  2.1473         \t|  0.0088794      \t|\n",
      "on_after_backward                  \t|  3.9496e-05     \t|51255          \t|  2.0244         \t|  0.0083711      \t|\n",
      "on_batch_end                       \t|  3.9019e-05     \t|51255          \t|  1.9999         \t|  0.0082701      \t|\n",
      "on_before_zero_grad                \t|  3.7996e-05     \t|51255          \t|  1.9475         \t|  0.0080531      \t|\n",
      "on_before_backward                 \t|  3.3383e-05     \t|51255          \t|  1.711          \t|  0.0070755      \t|\n",
      "on_before_optimizer_step           \t|  3.2625e-05     \t|51255          \t|  1.6722         \t|  0.0069147      \t|\n",
      "validation_step_end                \t|  8.6955e-06     \t|87002          \t|  0.75653        \t|  0.0031284      \t|\n",
      "training_step_end                  \t|  1.11e-05       \t|51255          \t|  0.56891        \t|  0.0023525      \t|\n",
      "on_validation_epoch_end            \t|  4.8852e-05     \t|1501           \t|  0.073327       \t|  0.00030322     \t|\n",
      "on_validation_epoch_start          \t|  3.3057e-05     \t|1501           \t|  0.049618       \t|  0.00020518     \t|\n",
      "on_epoch_start                     \t|  3.1172e-05     \t|1516           \t|  0.047256       \t|  0.00019541     \t|\n",
      "on_epoch_end                       \t|  3.0801e-05     \t|1516           \t|  0.046694       \t|  0.00019309     \t|\n",
      "on_train_epoch_start               \t|  0.0025337      \t|15             \t|  0.038006       \t|  0.00015716     \t|\n",
      "get_sanity_check_batch             \t|  0.011746       \t|3              \t|  0.035239       \t|  0.00014572     \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.011693       \t|3              \t|  0.035078       \t|  0.00014505     \t|\n",
      "on_train_start                     \t|  0.026505       \t|1              \t|  0.026505       \t|  0.0001096      \t|\n",
      "on_pretrain_routine_start          \t|  0.023737       \t|1              \t|  0.023737       \t|  9.8158e-05     \t|\n",
      "on_train_epoch_end                 \t|  0.001274       \t|15             \t|  0.019111       \t|  7.9026e-05     \t|\n",
      "configure_optimizers               \t|  0.0045612      \t|1              \t|  0.0045612      \t|  1.8861e-05     \t|\n",
      "on_sanity_check_start              \t|  0.0018107      \t|1              \t|  0.0018107      \t|  7.4877e-06     \t|\n",
      "on_train_end                       \t|  0.00090418     \t|1              \t|  0.00090418     \t|  3.7389e-06     \t|\n",
      "on_before_accelerator_backend_setup\t|  5.3496e-05     \t|1              \t|  5.3496e-05     \t|  2.2122e-07     \t|\n",
      "on_fit_end                         \t|  4.9803e-05     \t|1              \t|  4.9803e-05     \t|  2.0594e-07     \t|\n",
      "on_sanity_check_end                \t|  4.9363e-05     \t|1              \t|  4.9363e-05     \t|  2.0412e-07     \t|\n",
      "on_fit_start                       \t|  4.6538e-05     \t|1              \t|  4.6538e-05     \t|  1.9244e-07     \t|\n",
      "on_pretrain_routine_end            \t|  4.6249e-05     \t|1              \t|  4.6249e-05     \t|  1.9125e-07     \t|\n",
      "teardown                           \t|  4.3172e-05     \t|1              \t|  4.3172e-05     \t|  1.7852e-07     \t|\n",
      "on_configure_sharded_model         \t|  4.1857e-05     \t|1              \t|  4.1857e-05     \t|  1.7309e-07     \t|\n",
      "setup                              \t|  3.3856e-05     \t|1              \t|  3.3856e-05     \t|  1.4e-07        \t|\n",
      "configure_callbacks                \t|  1.4225e-05     \t|1              \t|  1.4225e-05     \t|  5.8823e-08     \t|\n",
      "configure_sharded_model            \t|  1.0177e-05     \t|1              \t|  1.0177e-05     \t|  4.2084e-08     \t|\n",
      "on_val_dataloader                  \t|  9.794e-06      \t|1              \t|  9.794e-06      \t|  4.05e-08       \t|\n",
      "on_train_dataloader                \t|  9.693e-06      \t|1              \t|  9.693e-06      \t|  4.0082e-08     \t|\n",
      "prepare_data                       \t|  9.242e-06      \t|1              \t|  9.242e-06      \t|  3.8217e-08     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 0.36, False, 'gelu', 16, 0.002, 5000, 0.03, 1e-06, 0.7, 1e-06, 40, 0.01, 'SimpleMultistepCosineLRS', False, 1.0, 0.0, False, 20, 1.0, 1.5, 0.01, 'CrossEntropyLoss', 0.25, 2.0, 10000000000.0)\n",
      "Getting TrainValTest batches\n",
      "207 70 36 313\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:00<00:00, 5164.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "264390 264390\n",
      "{0: 20.488312585491137, 1: 10.261026147155574, 2: 12.544115012309305, 3: 29.706546255073405}\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 4171.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "70317 70317\n",
      "{0: 7.313173609915914, 1: 1.146397844338393, 2: 3.8564953882948885, 3: 11.68393315745482}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                       | Params\n",
      "-------------------------------------------------------------\n",
      "0 | nested_module | B1hw_LayerResnetBottleneck | 311 K \n",
      "1 | prefix_layerD | Sequential                 | 0     \n",
      "2 | suffix_layerA | Sequential                 | 0     \n",
      "3 | suffix_layerD | Sequential                 | 230 K \n",
      "4 | suffix_layerZ | Sequential                 | 1.9 K \n",
      "5 | loss          | CrossEntropyLoss           | 0     \n",
      "-------------------------------------------------------------\n",
      "543 K     Trainable params\n",
      "0         Non-trainable params\n",
      "543 K     Total params\n",
      "2.173     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  94%|█████████▍| 7908/8417 [24:49<01:35,  5.31it/s, loss=0.954, v_num=8_49, train_loss_s=0.944, val_loss_s=1.440]10000 20000 0.001999\n",
      "Epoch 14: 100%|██████████| 8417/8417 [26:36<00:00,  5.27it/s, loss=0.94, v_num=8_49, train_loss_s=0.942, val_loss_s=1.470]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  2.4283e+04     \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1618.8         \t|15             \t|  2.4282e+04     \t|  99.995         \t|\n",
      "run_training_batch                 \t|  0.35299        \t|51255          \t|  1.8093e+04     \t|  74.508         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.35145        \t|51255          \t|  1.8014e+04     \t|  74.183         \t|\n",
      "training_step_and_backward         \t|  0.18052        \t|51255          \t|  9252.5         \t|  38.103         \t|\n",
      "backward                           \t|  0.1078         \t|51255          \t|  5525.2         \t|  22.753         \t|\n",
      "evaluation_step_and_end            \t|  0.052487       \t|75002          \t|  3936.6         \t|  16.212         \t|\n",
      "validation_step                    \t|  0.052381       \t|75002          \t|  3928.7         \t|  16.179         \t|\n",
      "model_forward                      \t|  0.070803       \t|51255          \t|  3629.0         \t|  14.945         \t|\n",
      "training_step                      \t|  0.070565       \t|51255          \t|  3616.8         \t|  14.894         \t|\n",
      "get_validate_batch                 \t|  0.0048887      \t|76500          \t|  373.99         \t|  1.5401         \t|\n",
      "fetch_next_validate_batch          \t|  0.0048583      \t|76500          \t|  371.66         \t|  1.5305         \t|\n",
      "on_train_batch_end                 \t|  0.0034233      \t|51255          \t|  175.46         \t|  0.72256        \t|\n",
      "on_validation_batch_end            \t|  0.0017401      \t|75002          \t|  130.51         \t|  0.53746        \t|\n",
      "zero_grad                          \t|  0.0018725      \t|51255          \t|  95.974         \t|  0.39523        \t|\n",
      "on_train_batch_start               \t|  0.0016827      \t|51255          \t|  86.248         \t|  0.35518        \t|\n",
      "on_validation_end                  \t|  0.048513       \t|1501           \t|  72.818         \t|  0.29987        \t|\n",
      "evaluation_batch_to_device         \t|  0.00060213     \t|75002          \t|  45.161         \t|  0.18598        \t|\n",
      "get_train_batch                    \t|  0.00084677     \t|51270          \t|  43.414         \t|  0.17878        \t|\n",
      "fetch_next_train_batch             \t|  0.00081676     \t|51270          \t|  41.875         \t|  0.17245        \t|\n",
      "training_batch_to_device           \t|  0.00036078     \t|51255          \t|  18.492         \t|  0.07615        \t|\n",
      "on_validation_start                \t|  0.00512        \t|1501           \t|  7.6852         \t|  0.031648       \t|\n",
      "on_validation_model_eval           \t|  0.0048369      \t|1501           \t|  7.2602         \t|  0.029898       \t|\n",
      "on_validation_batch_start          \t|  3.7692e-05     \t|75002          \t|  2.827          \t|  0.011642       \t|\n",
      "on_batch_start                     \t|  4.2356e-05     \t|51255          \t|  2.1709         \t|  0.0089402      \t|\n",
      "on_after_backward                  \t|  4.1884e-05     \t|51255          \t|  2.1468         \t|  0.0088407      \t|\n",
      "on_batch_end                       \t|  3.9181e-05     \t|51255          \t|  2.0082         \t|  0.0082701      \t|\n",
      "on_before_zero_grad                \t|  3.8028e-05     \t|51255          \t|  1.9491         \t|  0.0080268      \t|\n",
      "on_before_backward                 \t|  3.3224e-05     \t|51255          \t|  1.7029         \t|  0.0070127      \t|\n",
      "on_before_optimizer_step           \t|  3.2933e-05     \t|51255          \t|  1.688          \t|  0.0069514      \t|\n",
      "validation_step_end                \t|  8.8442e-06     \t|75002          \t|  0.66333        \t|  0.0027317      \t|\n",
      "training_step_end                  \t|  1.1123e-05     \t|51255          \t|  0.57013        \t|  0.0023479      \t|\n",
      "on_validation_epoch_end            \t|  4.8809e-05     \t|1501           \t|  0.073263       \t|  0.00030171     \t|\n",
      "get_sanity_check_batch             \t|  0.020425       \t|3              \t|  0.061276       \t|  0.00025234     \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.020365       \t|3              \t|  0.061095       \t|  0.0002516      \t|\n",
      "on_validation_epoch_start          \t|  3.3378e-05     \t|1501           \t|  0.0501         \t|  0.00020632     \t|\n",
      "on_epoch_start                     \t|  3.1553e-05     \t|1516           \t|  0.047834       \t|  0.00019699     \t|\n",
      "on_epoch_end                       \t|  3.0726e-05     \t|1516           \t|  0.04658        \t|  0.00019182     \t|\n",
      "on_train_epoch_start               \t|  0.0023441      \t|15             \t|  0.035162       \t|  0.0001448      \t|\n",
      "on_pretrain_routine_start          \t|  0.021443       \t|1              \t|  0.021443       \t|  8.8303e-05     \t|\n",
      "on_train_epoch_end                 \t|  0.0013122      \t|15             \t|  0.019683       \t|  8.1057e-05     \t|\n",
      "configure_optimizers               \t|  0.0041066      \t|1              \t|  0.0041066      \t|  1.6912e-05     \t|\n",
      "on_train_start                     \t|  0.0030899      \t|1              \t|  0.0030899      \t|  1.2724e-05     \t|\n",
      "on_sanity_check_start              \t|  0.0019014      \t|1              \t|  0.0019014      \t|  7.8304e-06     \t|\n",
      "on_train_end                       \t|  0.00091773     \t|1              \t|  0.00091773     \t|  3.7793e-06     \t|\n",
      "on_pretrain_routine_end            \t|  7.6741e-05     \t|1              \t|  7.6741e-05     \t|  3.1603e-07     \t|\n",
      "on_before_accelerator_backend_setup\t|  5.6651e-05     \t|1              \t|  5.6651e-05     \t|  2.333e-07      \t|\n",
      "on_configure_sharded_model         \t|  5.2452e-05     \t|1              \t|  5.2452e-05     \t|  2.16e-07       \t|\n",
      "on_sanity_check_end                \t|  5.1177e-05     \t|1              \t|  5.1177e-05     \t|  2.1075e-07     \t|\n",
      "on_fit_end                         \t|  4.7401e-05     \t|1              \t|  4.7401e-05     \t|  1.952e-07      \t|\n",
      "setup                              \t|  4.5206e-05     \t|1              \t|  4.5206e-05     \t|  1.8616e-07     \t|\n",
      "on_fit_start                       \t|  4.3782e-05     \t|1              \t|  4.3782e-05     \t|  1.803e-07      \t|\n",
      "teardown                           \t|  3.8414e-05     \t|1              \t|  3.8414e-05     \t|  1.5819e-07     \t|\n",
      "configure_sharded_model            \t|  2.8218e-05     \t|1              \t|  2.8218e-05     \t|  1.1621e-07     \t|\n",
      "configure_callbacks                \t|  2.3696e-05     \t|1              \t|  2.3696e-05     \t|  9.7583e-08     \t|\n",
      "on_train_dataloader                \t|  1.0398e-05     \t|1              \t|  1.0398e-05     \t|  4.282e-08      \t|\n",
      "prepare_data                       \t|  9.837e-06      \t|1              \t|  9.837e-06      \t|  4.051e-08      \t|\n",
      "on_val_dataloader                  \t|  7.794e-06      \t|1              \t|  7.794e-06      \t|  3.2097e-08     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 0.36, False, 'gelu', 16, 0.002, 5000, 0.03, 1e-06, 0.7, 1e-06, 40, 0.01, 'SimpleMultistepCosineLRS', False, 1.0, 0.0, False, 20, 1.0, 1.5, 0.01, 'CrossEntropyLoss', 0.25, 2.0, 10000000000.0)\n",
      "Getting TrainValTest batches\n",
      "210 70 33 313\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [00:00<00:00, 7404.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "188273 188273\n",
      "{0: 17.469871056859304, 1: 6.685181895191551, 2: 12.356958375266036, 3: 31.487988672686495}\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 2050.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "124872 124872\n",
      "{0: 6.8075900442477435, 1: 2.9074466971687696, 2: 4.042690983164212, 3: 8.242272275428633}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                       | Params\n",
      "-------------------------------------------------------------\n",
      "0 | nested_module | B1hw_LayerResnetBottleneck | 311 K \n",
      "1 | prefix_layerD | Sequential                 | 0     \n",
      "2 | suffix_layerA | Sequential                 | 0     \n",
      "3 | suffix_layerD | Sequential                 | 230 K \n",
      "4 | suffix_layerZ | Sequential                 | 1.9 K \n",
      "5 | loss          | CrossEntropyLoss           | 0     \n",
      "-------------------------------------------------------------\n",
      "543 K     Trainable params\n",
      "0         Non-trainable params\n",
      "543 K     Total params\n",
      "2.173     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  94%|█████████▍| 5955/6317 [23:58<01:27,  4.14it/s, loss=0.937, v_num=0_51, train_loss_s=0.938, val_loss_s=1.470]10000 20000 0.001999\n",
      "Epoch 14: 100%|██████████| 6317/6317 [24:57<00:00,  4.22it/s, loss=0.925, v_num=0_51, train_loss_s=0.924, val_loss_s=1.490]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  2.2825e+04     \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1521.5         \t|15             \t|  2.2823e+04     \t|  99.994         \t|\n",
      "run_training_batch                 \t|  0.35333        \t|51255          \t|  1.811e+04      \t|  79.344         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.35183        \t|51255          \t|  1.8033e+04     \t|  79.008         \t|\n",
      "training_step_and_backward         \t|  0.18009        \t|51255          \t|  9230.5         \t|  40.441         \t|\n",
      "backward                           \t|  0.10808        \t|51255          \t|  5539.8         \t|  24.271         \t|\n",
      "model_forward                      \t|  0.070113       \t|51255          \t|  3593.6         \t|  15.745         \t|\n",
      "training_step                      \t|  0.069876       \t|51255          \t|  3581.5         \t|  15.691         \t|\n",
      "evaluation_step_and_end            \t|  0.058864       \t|43502          \t|  2560.7         \t|  11.219         \t|\n",
      "validation_step                    \t|  0.058758       \t|43502          \t|  2556.1         \t|  11.199         \t|\n",
      "get_validate_batch                 \t|  0.0090315      \t|45000          \t|  406.42         \t|  1.7806         \t|\n",
      "fetch_next_validate_batch          \t|  0.0089999      \t|45000          \t|  405.0          \t|  1.7744         \t|\n",
      "on_train_batch_end                 \t|  0.0034022      \t|51255          \t|  174.38         \t|  0.764          \t|\n",
      "zero_grad                          \t|  0.0018493      \t|51255          \t|  94.785         \t|  0.41527        \t|\n",
      "on_train_batch_start               \t|  0.0016746      \t|51255          \t|  85.83          \t|  0.37604        \t|\n",
      "on_validation_batch_end            \t|  0.0017591      \t|43502          \t|  76.523         \t|  0.33526        \t|\n",
      "on_validation_end                  \t|  0.033033       \t|1501           \t|  49.583         \t|  0.21723        \t|\n",
      "get_train_batch                    \t|  0.00082362     \t|51270          \t|  42.227         \t|  0.18501        \t|\n",
      "fetch_next_train_batch             \t|  0.00079377     \t|51270          \t|  40.697         \t|  0.1783         \t|\n",
      "evaluation_batch_to_device         \t|  0.000595       \t|43502          \t|  25.884         \t|  0.1134         \t|\n",
      "training_batch_to_device           \t|  0.00037372     \t|51255          \t|  19.155         \t|  0.083922       \t|\n",
      "on_validation_model_eval           \t|  0.0048885      \t|1501           \t|  7.3376         \t|  0.032148       \t|\n",
      "on_validation_start                \t|  0.004597       \t|1501           \t|  6.9001         \t|  0.030231       \t|\n",
      "on_batch_start                     \t|  4.2502e-05     \t|51255          \t|  2.1785         \t|  0.0095443      \t|\n",
      "on_after_backward                  \t|  4.1166e-05     \t|51255          \t|  2.11           \t|  0.0092443      \t|\n",
      "on_batch_end                       \t|  3.9341e-05     \t|51255          \t|  2.0164         \t|  0.0088345      \t|\n",
      "on_before_zero_grad                \t|  3.8486e-05     \t|51255          \t|  1.9726         \t|  0.0086425      \t|\n",
      "on_validation_batch_start          \t|  3.9566e-05     \t|43502          \t|  1.7212         \t|  0.007541       \t|\n",
      "on_before_backward                 \t|  3.326e-05      \t|51255          \t|  1.7048         \t|  0.0074689      \t|\n",
      "on_before_optimizer_step           \t|  3.2662e-05     \t|51255          \t|  1.6741         \t|  0.0073345      \t|\n",
      "training_step_end                  \t|  1.1051e-05     \t|51255          \t|  0.5664         \t|  0.0024815      \t|\n",
      "validation_step_end                \t|  8.896e-06      \t|43502          \t|  0.38699        \t|  0.0016955      \t|\n",
      "on_validation_epoch_end            \t|  4.9452e-05     \t|1501           \t|  0.074228       \t|  0.00032521     \t|\n",
      "get_sanity_check_batch             \t|  0.023096       \t|3              \t|  0.069288       \t|  0.00030357     \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.023042       \t|3              \t|  0.069125       \t|  0.00030285     \t|\n",
      "on_validation_epoch_start          \t|  3.3928e-05     \t|1501           \t|  0.050926       \t|  0.00022312     \t|\n",
      "on_epoch_start                     \t|  3.1669e-05     \t|1516           \t|  0.048011       \t|  0.00021035     \t|\n",
      "on_epoch_end                       \t|  3.1166e-05     \t|1516           \t|  0.047247       \t|  0.000207       \t|\n",
      "on_train_epoch_start               \t|  0.0024881      \t|15             \t|  0.037322       \t|  0.00016352     \t|\n",
      "on_train_epoch_end                 \t|  0.0013876      \t|15             \t|  0.020815       \t|  9.1194e-05     \t|\n",
      "on_pretrain_routine_start          \t|  0.020321       \t|1              \t|  0.020321       \t|  8.9033e-05     \t|\n",
      "configure_optimizers               \t|  0.0036683      \t|1              \t|  0.0036683      \t|  1.6072e-05     \t|\n",
      "on_train_start                     \t|  0.00313        \t|1              \t|  0.00313        \t|  1.3713e-05     \t|\n",
      "on_sanity_check_start              \t|  0.0016748      \t|1              \t|  0.0016748      \t|  7.3378e-06     \t|\n",
      "on_train_end                       \t|  0.00098341     \t|1              \t|  0.00098341     \t|  4.3086e-06     \t|\n",
      "on_sanity_check_end                \t|  5.4124e-05     \t|1              \t|  5.4124e-05     \t|  2.3713e-07     \t|\n",
      "on_fit_end                         \t|  5.216e-05      \t|1              \t|  5.216e-05      \t|  2.2853e-07     \t|\n",
      "teardown                           \t|  4.901e-05      \t|1              \t|  4.901e-05      \t|  2.1472e-07     \t|\n",
      "on_pretrain_routine_end            \t|  4.8848e-05     \t|1              \t|  4.8848e-05     \t|  2.1402e-07     \t|\n",
      "on_before_accelerator_backend_setup\t|  4.1624e-05     \t|1              \t|  4.1624e-05     \t|  1.8236e-07     \t|\n",
      "on_configure_sharded_model         \t|  4.115e-05      \t|1              \t|  4.115e-05      \t|  1.8029e-07     \t|\n",
      "on_fit_start                       \t|  3.8131e-05     \t|1              \t|  3.8131e-05     \t|  1.6706e-07     \t|\n",
      "setup                              \t|  3.2803e-05     \t|1              \t|  3.2803e-05     \t|  1.4372e-07     \t|\n",
      "configure_callbacks                \t|  1.4781e-05     \t|1              \t|  1.4781e-05     \t|  6.4759e-08     \t|\n",
      "on_train_dataloader                \t|  1.0795e-05     \t|1              \t|  1.0795e-05     \t|  4.7296e-08     \t|\n",
      "configure_sharded_model            \t|  9.972e-06      \t|1              \t|  9.972e-06      \t|  4.369e-08      \t|\n",
      "on_val_dataloader                  \t|  7.817e-06      \t|1              \t|  7.817e-06      \t|  3.4248e-08     \t|\n",
      "prepare_data                       \t|  6.977e-06      \t|1              \t|  6.977e-06      \t|  3.0568e-08     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 0.36, False, 'gelu', 16, 0.002, 5000, 0.03, 1e-06, 0.7, 1e-06, 40, 0.01, 'SimpleMultistepCosineLRS', False, 1.0, 0.0, False, 20, 1.0, 1.5, 0.01, 'CrossEntropyLoss', 0.25, 2.0, 10000000000.0)\n",
      "Getting TrainValTest batches\n",
      "209 73 31 313\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 209/209 [00:00<00:00, 3589.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "272361 272361\n",
      "{0: 20.71123523471334, 1: 8.295204926323487, 2: 11.501889978546158, 3: 30.491669860350058}\n",
      "Concating Dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 3151.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Concat data. Cooling down\n",
      "61392 61392\n",
      "{0: 5.039109713616278, 1: 2.8233504771883333, 2: 4.847154990105763, 3: 10.290384819090676}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                       | Params\n",
      "-------------------------------------------------------------\n",
      "0 | nested_module | B1hw_LayerResnetBottleneck | 311 K \n",
      "1 | prefix_layerD | Sequential                 | 0     \n",
      "2 | suffix_layerA | Sequential                 | 0     \n",
      "3 | suffix_layerD | Sequential                 | 230 K \n",
      "4 | suffix_layerZ | Sequential                 | 1.9 K \n",
      "5 | loss          | CrossEntropyLoss           | 0     \n",
      "-------------------------------------------------------------\n",
      "543 K     Trainable params\n",
      "0         Non-trainable params\n",
      "543 K     Total params\n",
      "2.173     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2:  94%|█████████▍| 8652/9217 [24:42<01:36,  5.84it/s, loss=0.951, v_num=2_53, train_loss_s=0.947, val_loss_s=1.470]10000 20000 0.001999\n",
      "Epoch 14: 100%|██████████| 9217/9217 [27:05<00:00,  5.67it/s, loss=0.94, v_num=2_53, train_loss_s=0.931, val_loss_s=1.460]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "Action                             \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Total                              \t|  -              \t|_              \t|  2.4111e+04     \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch                 \t|  1607.3         \t|15             \t|  2.411e+04      \t|  99.995         \t|\n",
      "run_training_batch                 \t|  0.34351        \t|51255          \t|  1.7607e+04     \t|  73.023         \t|\n",
      "optimizer_step_with_closure_0      \t|  0.34208        \t|51255          \t|  1.7533e+04     \t|  72.719         \t|\n",
      "training_step_and_backward         \t|  0.17583        \t|51255          \t|  9012.0         \t|  37.377         \t|\n",
      "backward                           \t|  0.10484        \t|51255          \t|  5373.5         \t|  22.286         \t|\n",
      "evaluation_step_and_end            \t|  0.049199       \t|87002          \t|  4280.4         \t|  17.753         \t|\n",
      "validation_step                    \t|  0.049096       \t|87002          \t|  4271.5         \t|  17.716         \t|\n",
      "model_forward                      \t|  0.069114       \t|51255          \t|  3542.4         \t|  14.692         \t|\n",
      "training_step                      \t|  0.06888        \t|51255          \t|  3530.4         \t|  14.642         \t|\n",
      "get_validate_batch                 \t|  0.0040877      \t|88500          \t|  361.76         \t|  1.5004         \t|\n",
      "fetch_next_validate_batch          \t|  0.0040583      \t|88500          \t|  359.16         \t|  1.4896         \t|\n",
      "on_train_batch_end                 \t|  0.0031668      \t|51255          \t|  162.31         \t|  0.6732         \t|\n",
      "on_validation_batch_end            \t|  0.0015209      \t|87002          \t|  132.32         \t|  0.54878        \t|\n",
      "zero_grad                          \t|  0.0018319      \t|51255          \t|  93.892         \t|  0.38941        \t|\n",
      "on_train_batch_start               \t|  0.0016795      \t|51255          \t|  86.084         \t|  0.35703        \t|\n",
      "on_validation_end                  \t|  0.050721       \t|1501           \t|  76.132         \t|  0.31576        \t|\n",
      "evaluation_batch_to_device         \t|  0.00058002     \t|87002          \t|  50.463         \t|  0.20929        \t|\n",
      "get_train_batch                    \t|  0.00081602     \t|51270          \t|  41.837         \t|  0.17352        \t|\n",
      "fetch_next_train_batch             \t|  0.00078666     \t|51270          \t|  40.332         \t|  0.16728        \t|\n",
      "training_batch_to_device           \t|  0.00037141     \t|51255          \t|  19.037         \t|  0.078955       \t|\n",
      "on_validation_model_eval           \t|  0.0048305      \t|1501           \t|  7.2505         \t|  0.030071       \t|\n",
      "on_validation_start                \t|  0.0047471      \t|1501           \t|  7.1254         \t|  0.029552       \t|\n",
      "on_validation_batch_start          \t|  3.6485e-05     \t|87002          \t|  3.1743         \t|  0.013165       \t|\n",
      "on_batch_start                     \t|  4.2232e-05     \t|51255          \t|  2.1646         \t|  0.0089776      \t|\n",
      "on_after_backward                  \t|  3.951e-05      \t|51255          \t|  2.0251         \t|  0.008399       \t|\n",
      "on_batch_end                       \t|  3.907e-05      \t|51255          \t|  2.0025         \t|  0.0083053      \t|\n",
      "on_before_zero_grad                \t|  3.7765e-05     \t|51255          \t|  1.9356         \t|  0.008028       \t|\n",
      "on_before_backward                 \t|  3.2938e-05     \t|51255          \t|  1.6882         \t|  0.0070019      \t|\n",
      "on_before_optimizer_step           \t|  3.2471e-05     \t|51255          \t|  1.6643         \t|  0.0069026      \t|\n",
      "validation_step_end                \t|  8.6668e-06     \t|87002          \t|  0.75403        \t|  0.0031273      \t|\n",
      "training_step_end                  \t|  1.0941e-05     \t|51255          \t|  0.5608         \t|  0.0023259      \t|\n",
      "on_validation_epoch_end            \t|  4.8667e-05     \t|1501           \t|  0.07305        \t|  0.00030297     \t|\n",
      "on_validation_epoch_start          \t|  3.2912e-05     \t|1501           \t|  0.0494         \t|  0.00020489     \t|\n",
      "on_epoch_start                     \t|  3.1177e-05     \t|1516           \t|  0.047264       \t|  0.00019603     \t|\n",
      "on_epoch_end                       \t|  3.0689e-05     \t|1516           \t|  0.046525       \t|  0.00019296     \t|\n",
      "get_sanity_check_batch             \t|  0.012109       \t|3              \t|  0.036327       \t|  0.00015066     \t|\n",
      "fetch_next_sanity_check_batch      \t|  0.01205        \t|3              \t|  0.03615        \t|  0.00014993     \t|\n",
      "on_train_epoch_start               \t|  0.0023889      \t|15             \t|  0.035833       \t|  0.00014862     \t|\n",
      "on_pretrain_routine_start          \t|  0.020286       \t|1              \t|  0.020286       \t|  8.4137e-05     \t|\n",
      "on_train_epoch_end                 \t|  0.0012484      \t|15             \t|  0.018725       \t|  7.7663e-05     \t|\n",
      "configure_optimizers               \t|  0.0036588      \t|1              \t|  0.0036588      \t|  1.5175e-05     \t|\n",
      "on_train_start                     \t|  0.0030322      \t|1              \t|  0.0030322      \t|  1.2576e-05     \t|\n",
      "on_sanity_check_start              \t|  0.0013763      \t|1              \t|  0.0013763      \t|  5.7083e-06     \t|\n",
      "on_train_end                       \t|  0.00095244     \t|1              \t|  0.00095244     \t|  3.9502e-06     \t|\n",
      "on_fit_end                         \t|  4.9713e-05     \t|1              \t|  4.9713e-05     \t|  2.0618e-07     \t|\n",
      "teardown                           \t|  4.9094e-05     \t|1              \t|  4.9094e-05     \t|  2.0362e-07     \t|\n",
      "on_sanity_check_end                \t|  4.7481e-05     \t|1              \t|  4.7481e-05     \t|  1.9693e-07     \t|\n",
      "on_pretrain_routine_end            \t|  4.0947e-05     \t|1              \t|  4.0947e-05     \t|  1.6983e-07     \t|\n",
      "on_before_accelerator_backend_setup\t|  4.0564e-05     \t|1              \t|  4.0564e-05     \t|  1.6824e-07     \t|\n",
      "on_configure_sharded_model         \t|  4.0302e-05     \t|1              \t|  4.0302e-05     \t|  1.6715e-07     \t|\n",
      "on_fit_start                       \t|  3.7608e-05     \t|1              \t|  3.7608e-05     \t|  1.5598e-07     \t|\n",
      "setup                              \t|  3.3667e-05     \t|1              \t|  3.3667e-05     \t|  1.3963e-07     \t|\n",
      "configure_callbacks                \t|  1.6278e-05     \t|1              \t|  1.6278e-05     \t|  6.7512e-08     \t|\n",
      "configure_sharded_model            \t|  1.2235e-05     \t|1              \t|  1.2235e-05     \t|  5.0744e-08     \t|\n",
      "on_train_dataloader                \t|  1.0768e-05     \t|1              \t|  1.0768e-05     \t|  4.466e-08      \t|\n",
      "on_val_dataloader                  \t|  7.663e-06      \t|1              \t|  7.663e-06      \t|  3.1782e-08     \t|\n",
      "prepare_data                       \t|  7.195e-06      \t|1              \t|  7.195e-06      \t|  2.9841e-08     \t|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cccc in CombinationList:\n",
    "  for User_SelectedCrossFoldIndex in [ 0,3,6]:\n",
    "\n",
    "    print(cccc)\n",
    "    # ==========================\n",
    "    # Hyperparam \n",
    "    # ===============================\n",
    "    PART0_InitialiseHyperparameters = True\n",
    "    if PART0_InitialiseHyperparameters:\n",
    "    # ==========================\n",
    "    # Hyperparam \n",
    "    # ===============================\n",
    "\n",
    "        User_SizeMinibatch = cccc[0] #256 \n",
    "        User_LabelSmoothing = cccc[1] #0.16 \n",
    "        User_PerformReduction = cccc[2] #True \n",
    "        User_Activation = cccc[3] #'gelu'\n",
    "        User_n_ResnetBlock = cccc[4]#16 \n",
    "        User_lr = cccc[5] #1e-3      \n",
    "        n_Restart = 1  \n",
    "        User_CooldownInterval = cccc[6] #951\n",
    "        User_AdamW_weight_decay = cccc[7] #1e-2\n",
    "        User_min_lr = cccc[8] #1e-6\n",
    "\n",
    "\n",
    "        User_Dropoutp = cccc[9]\n",
    "        User_AddL1 = cccc[10]\n",
    "        User_n_channelbottleneck = cccc[11]\n",
    "        User_ShiftLrRatio = cccc[12]\n",
    "\n",
    "\n",
    "        # NOTE Currently fixed for benchmarking\n",
    "        User_LrScheduler = cccc[13]   \n",
    "        User_BiasInSuffixFc = cccc[14]\n",
    "        User_NoiseX = cccc[15]\n",
    "        User_NoiseY = cccc[16]\n",
    "        User_Mixup = cccc[17] # NOTE Not used.\n",
    "        User_NumReductionComponent = cccc[18]\n",
    "        User_NoiseZ = cccc[19]\n",
    "        User_NeighborLabelSmoothAngstrom = cccc[20]\n",
    "        User_InputDropoutp = cccc[21]\n",
    "        User_Loss = cccc[22]\n",
    "        User_FocalLossAlpha = cccc[23]\n",
    "        User_FocalLossGamma = cccc[24]\n",
    "        User_GradientClippingValue = cccc[25]\n",
    "        #print(User_GradientClippingValue)\n",
    "        #sys.exit()\n",
    "\n",
    "        FetchDatasetC = FetchDataset(\n",
    "            DIR_DerivedData = DIR_DerivedData,\n",
    "            DIR_Typi = DIR_Typi,\n",
    "            DIR_FuelInput = DIR_FuelInput,\n",
    "            User_DesiredDatasize    = User_DesiredBatchDatasize, # NOTE This controls the number of new batch of dataset-dataloader being reloaded into memory\n",
    "            User_SampleSizePerEpoch_Factor = User_SampleSizePerEpoch_Factor, # NOTE This controls how much sample enters into an epoch\n",
    "            User_featuretype = User_featuretype,\n",
    "            n_datasetworker = n_datasetworker,\n",
    "            ClanGraphBcPercent = ClanGraphBcPercent)\n",
    "\n",
    "        classindex_str = sorted(TaskNameLabelLogicDict[User_Task].keys()) \n",
    "        ClassName_ClassIndex_Dict = dict(zip(classindex_str, range(len(classindex_str))))\n",
    "\n",
    "    # ============================\n",
    "    # Get Cross-Folds and Batches\n",
    "    # ============================\n",
    "    print(\"Getting TrainValTest batches\")\n",
    "    PART1A_GetCrossFolds = True\n",
    "    if PART1A_GetCrossFolds:\n",
    "\n",
    "        # NOTE Pdbids, Datasize weight\n",
    "        Train_PdbidBatches, TrainFold_PdbidSamplingWeight = CrossFoldDfList[User_SelectedCrossFoldIndex][0]\n",
    "        Val_PdbidBatches, ValFold_PdbidSamplingWeight = CrossFoldDfList[User_SelectedCrossFoldIndex][1]\n",
    "        Testing_PdbidBatches,TestingFold_PdbidSamplingWeight  = CrossFoldDfList[User_SelectedCrossFoldIndex][2]\n",
    "\n",
    "        print(len(Train_PdbidBatches), len(Val_PdbidBatches), len(Testing_PdbidBatches), len(set(Testing_PdbidBatches+Val_PdbidBatches+Train_PdbidBatches)))\n",
    "        Train_PdbidWeight = dict(\n",
    "                TrainFold_PdbidSamplingWeight[[\"Pdbid\", \"PdbidSamplingWeight\"]].values.tolist()\n",
    "                )\n",
    "        Val_PdbidWeight = dict(\n",
    "                ValFold_PdbidSamplingWeight[[\"Pdbid\", \"PdbidSamplingWeight\"]].values.tolist()\n",
    "                )\n",
    "        Testing_PdbidWeight = dict(\n",
    "                TestingFold_PdbidSamplingWeight[[\"Pdbid\", \"PdbidSamplingWeight\"]].values.tolist()\n",
    "                )\n",
    "\n",
    "    PART1B_DatasetDataloader = True\n",
    "    if PART1B_DatasetDataloader:\n",
    "        # NOTE Train\n",
    "        ds_train, ds_train_samplingweight = FetchDatasetC.GetDataset(\n",
    "                        Assigned_PdbidBatch = Train_PdbidBatches,\n",
    "                        Assigned_PdbidWeight = Train_PdbidWeight,\n",
    "                        User_NumReductionComponent = User_NumReductionComponent,\n",
    "                        ClassName_ClassIndex_Dict = ClassName_ClassIndex_Dict,\n",
    "                        User_Task = User_Task,\n",
    "                        PerformZscoring = True, \n",
    "                        PerformReduction = User_PerformReduction,\n",
    "                        User_NeighborLabelSmoothAngstrom = User_NeighborLabelSmoothAngstrom \n",
    "                        )\n",
    "                        \n",
    "        train_sampler = torch.utils.data.sampler.WeightedRandomSampler(\n",
    "                        ds_train_samplingweight, User_SampleSizePerEpoch, replacement=True)\n",
    "        train_loader  = torch.utils.data.DataLoader(ds_train, batch_size=User_SizeMinibatch, drop_last=True, num_workers=4, \n",
    "                                                            pin_memory=True,worker_init_fn=None, prefetch_factor=3, persistent_workers=False,\n",
    "                                                            sampler = train_sampler)\n",
    "\n",
    "        # NOTE Val\n",
    "        ds_val, ds_val_samplingweight = FetchDatasetC.GetDataset(\n",
    "                        Assigned_PdbidBatch = Val_PdbidBatches,\n",
    "                        Assigned_PdbidWeight = Val_PdbidWeight,\n",
    "                        User_NumReductionComponent = User_NumReductionComponent,\n",
    "                        ClassName_ClassIndex_Dict = ClassName_ClassIndex_Dict,\n",
    "                        User_Task = User_Task,\n",
    "                        PerformZscoring = True, \n",
    "                        PerformReduction = User_PerformReduction,\n",
    "                        User_NeighborLabelSmoothAngstrom = User_NeighborLabelSmoothAngstrom \n",
    "                        )\n",
    "        val_sampler = torch.utils.data.sampler.WeightedRandomSampler(\n",
    "            ds_val_samplingweight, int(User_SampleSizePerEpoch/100), replacement=True)\n",
    "        val_loader          = torch.utils.data.DataLoader(ds_val, batch_size=int(ds_val.__len__()/100), drop_last=False, num_workers=4, \n",
    "                                                            pin_memory=True,worker_init_fn=None, prefetch_factor=3, persistent_workers=False,\n",
    "                                                            shuffle=False, sampler = val_sampler)  \n",
    "\n",
    "        #NOTE Test\n",
    "        \"\"\"\n",
    "        ds_testing, ds_testing_samplingweight = FetchDatasetC.GetDataset(\n",
    "                        Assigned_PdbidBatch = Testing_PdbidBatches,\n",
    "                        Assigned_PdbidWeight = Testing_PdbidWeight,\n",
    "                        User_NumReductionComponent = User_NumReductionComponent,\n",
    "                        ClassName_ClassIndex_Dict = ClassName_ClassIndex_Dict,\n",
    "                        User_Task = User_Task,\n",
    "                        PerformZscoring = True, \n",
    "                        PerformReduction = User_PerformReduction,\n",
    "                        )\n",
    "        \n",
    "        testing_sampler = torch.utils.data.sampler.WeightedRandomSampler(\n",
    "            ds_testing_samplingweight, int(User_SampleSizePerEpoch/100), replacement=True)\n",
    "        testing_loader          = torch.utils.data.DataLoader(ds_testing, batch_size=int(ds_testing.__len__()/100), drop_last=False, \n",
    "                                                            num_workers=4, \n",
    "                                                            pin_memory=True,worker_init_fn=None, prefetch_factor=3, persistent_workers=False,\n",
    "                                                            shuffle=False, sampler = testing_sampler) \n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    # =====================\n",
    "    # Define Model\n",
    "    # ======================\n",
    "    PART2_DefineModel = True\n",
    "    if PART2_DefineModel:\n",
    "        if User_PerformReduction:\n",
    "            n_FeatPerShell = User_NumReductionComponent\n",
    "            hw_product = n_FeatPerShell*6\n",
    "        else:\n",
    "            n_FeatPerShell = 80\n",
    "            hw_product = 80*6\n",
    "\n",
    "        model = NucleicNet.Burn.M1.B1hw_FcLogits(\n",
    "                        model   = NucleicNet.Burn.M1.B1hw_LayerResnetBottleneck(n_FeatPerShell = n_FeatPerShell, \n",
    "                                                    n_Shell = 6,\n",
    "                                                    n_ShellMix = 2,\n",
    "                                                    User_Activation = User_Activation,\n",
    "                                                    User_Block = \"B1hw_BlockPreActResnet\",\n",
    "                                                    n_Blocks = User_n_ResnetBlock,\n",
    "                                                    ManualInitiation = False,\n",
    "                                                    User_n_channelbottleneck = User_n_channelbottleneck,\n",
    "                                                    User_NoiseZ = User_NoiseZ,\n",
    "                                                    ),\n",
    "\n",
    "                        #loss    = customloss, \n",
    "                        User_Loss = User_Loss, \n",
    "                        n_class = 4,\n",
    "                        hw_product = hw_product,\n",
    "                        AddMultiLabelSoftMarginLoss = False, # TODO Worsen stuff? One-vs-all likely of no use.\n",
    "                        User_lr = User_lr,\n",
    "                        User_min_lr = User_min_lr,\n",
    "                        User_LrScheduler = User_LrScheduler,\n",
    "                        User_CooldownInterval = User_CooldownInterval,\n",
    "                        BiasInSuffixFc = User_BiasInSuffixFc, \n",
    "                        # NOTE some kwargs for hparam record\n",
    "                        User_SizeMinibatch = User_SizeMinibatch,\n",
    "                        User_LabelSmoothing = User_LabelSmoothing,\n",
    "                        User_PerformReduction = User_PerformReduction,\n",
    "                        User_n_ResnetBlock = User_n_ResnetBlock,\n",
    "                        User_AdamW_weight_decay = User_AdamW_weight_decay,\n",
    "                        User_Activation = User_Activation,\n",
    "                        User_SelectedCrossFoldIndex = User_SelectedCrossFoldIndex,\n",
    "                        User_Dropoutp = User_Dropoutp,\n",
    "                        User_AddL1 = User_AddL1,\n",
    "                        User_n_channelbottleneck = User_n_channelbottleneck,\n",
    "                        User_ShiftLrRatio = User_ShiftLrRatio,\n",
    "                        User_NoiseX = User_NoiseX,\n",
    "                        User_NoiseY = User_NoiseY,\n",
    "                        #User_Mixup = User_Mixup,\n",
    "                        User_NumReductionComponent = User_NumReductionComponent,\n",
    "                        User_NoiseZ = User_NoiseZ,\n",
    "                        User_PdbidTraining = Train_PdbidBatches,\n",
    "                        User_PdbidValidation = Val_PdbidBatches,\n",
    "                        User_PdbidTesting = Testing_PdbidBatches,\n",
    "                        User_InputDropoutp = User_InputDropoutp,\n",
    "                        User_FocalLossAlpha = User_FocalLossAlpha,\n",
    "                        User_FocalLossGamma = User_FocalLossGamma,\n",
    "                        User_n_CrossFold = n_CrossFold,\n",
    "                        User_ClanGraphBcPercent = ClanGraphBcPercent,\n",
    "                        User_Task = User_Task,\n",
    "                        User_NeighborLabelSmoothAngstrom = User_NeighborLabelSmoothAngstrom,\n",
    "                        User_GradientClippingValue = User_GradientClippingValue,\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "        NucleicNet.Burn.util.ResetAllParameters(model)\n",
    "\n",
    "\n",
    "\n",
    "    # ====================\n",
    "    # Stage 0 training\n",
    "    # ====================\n",
    "    trainer00 = NucleicNet.Burn.util.DefaultTrainer00(DIR_TrainLog = DIR_TrainLog, \n",
    "                                                        DIR_TrainingRoot = DIR_TrainingRoot, \n",
    "                                                        User_ExperiementName = User_ExperiementName,\n",
    "                                                        User_SizeMinibatch = User_SizeMinibatch ,\n",
    "                                                        User_ShiftLrRatio = User_ShiftLrRatio,\n",
    "                                                        User_Mixup = User_Mixup,\n",
    "                                                        User_GradientClippingValue = User_GradientClippingValue)\n",
    "    trainer00.logger._log_graph = True \n",
    "    trainer00.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "\n",
    "\n",
    "    del model, trainer00\n",
    "    gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epilogue\n",
    "\n",
    "Remember to train SXPR before moving on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5f598b2da1a38c0fbc1071e0920cd7e6bcaf63d50063efd89e5e41621a15766f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('JQCB': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
